# -*- coding: utf-8 -*-
"""
ç•°æ­¥ Google Gemini AI æœå‹™æ¨¡çµ„ã€‚

æ­¤æ¨¡çµ„æä¾›äº† `AsyncGeminiService` é¡åˆ¥ï¼Œç”¨æ–¼èˆ‡ Google Gemini AI æ¨¡å‹é€²è¡Œç•°æ­¥äº’å‹•ã€‚
ä¸»è¦åŠŸèƒ½åŒ…æ‹¬ï¼š
- ç”Ÿæˆå„ç¨®é•·åº¦æ–‡æœ¬çš„æ‘˜è¦ (å®Œæ•´æ‘˜è¦ã€é‡é»æ‘˜è¦ã€çµæ§‹åŒ–æ‘˜è¦ã€åˆ†æ®µæ‘˜è¦)ã€‚
- è™•ç† API é‡‘é‘°è¼ªæ›å’Œè«‹æ±‚é‡è©¦æ©Ÿåˆ¶ã€‚
- æå–ä¸¦æ¨™æº–åŒ– Gemini API çš„å›æ‡‰ã€‚
- (å¯é¸æ“´å±•) æ–‡æœ¬æƒ…æ„Ÿåˆ†æã€é—œéµå­—æå–ç­‰ã€‚

æ­¤æœå‹™è¨­è¨ˆç‚ºå¯é…ç½®çš„ï¼Œå…è¨±é€é `AppConfig` å‚³å…¥ API é‡‘é‘°ã€æ¨¡å‹åç¨±ç­‰åƒæ•¸ã€‚
"""

import logging
import asyncio # ç”¨æ–¼ç•°æ­¥æ“ä½œï¼Œä¾‹å¦‚ await asyncio.sleep()
# åœ¨æª”æ¡ˆé ‚éƒ¨ï¼Œç¢ºä¿ time è¢«å°å…¥
import time
from typing import Dict, Any, Optional, List
import json
import random
from google import genai
from google.genai import types

from config import AppConfig

logger = logging.getLogger(__name__)


class AsyncGeminiService:
    """ç•°æ­¥Google Gemini AIæœå‹™"""
    
    def __init__(self, config: AppConfig):
        self.config = config
import time # å°å…¥ time æ¨¡çµ„
from typing import Dict, Any, Optional, List
import json
import random # random æœªåœ¨æ­¤æª”æ¡ˆç›´æ¥ä½¿ç”¨ï¼Œä½†ä¿ç•™ä»¥å‚™æœªä¾†æ“´å±•
from google import genai
from google.generativeai import types as genai_types # ä½¿ç”¨åˆ¥åä»¥é¿å…èˆ‡ typing.types è¡çªï¼Œä¸¦æ›´æ¸…æ™°

from config import AppConfig

logger = logging.getLogger(__name__)


class AsyncGeminiService:
    """
    ç•°æ­¥ Google Gemini AI æœå‹™é¡åˆ¥ã€‚

    æä¾›èˆ‡ Google Gemini æ¨¡å‹äº’å‹•çš„æ–¹æ³•ï¼Œä¸»è¦ç”¨æ–¼ç”Ÿæˆæ–‡æœ¬æ‘˜è¦ã€‚
    æ”¯æŒåŸºæ–¼æ–‡æœ¬é•·åº¦çš„ä¸åŒæ‘˜è¦ç­–ç•¥ï¼Œä¸¦åŒ…å« API é‡‘é‘°è¼ªæ›å’Œé‡è©¦æ©Ÿåˆ¶ã€‚
    """
    
    def __init__(self, config: AppConfig):
        """
        åˆå§‹åŒ– AsyncGeminiServiceã€‚

        Args:
            config (AppConfig): æ‡‰ç”¨ç¨‹å¼çš„çµ„æ…‹è¨­å®šç‰©ä»¶ï¼ŒåŒ…å« Google API é‡‘é‘°ã€
                                Gemini æ¨¡å‹åç¨±ã€é‡è©¦æ¬¡æ•¸å’Œå»¶é²ç­‰åƒæ•¸ã€‚
        
        Raises:
            ValueError: å¦‚æœçµ„æ…‹ä¸­æœªæä¾› Google API é‡‘é‘°ã€‚
        """
        self.config = config
        self.api_keys: List[str] = config.GOOGLE_API_KEYS # å¾ AppConfig ç²å– Google API é‡‘é‘°åˆ—è¡¨
        self.model_name: str = config.AI_MODEL_NAME # å¾ AppConfig ç²å–è¦ä½¿ç”¨çš„ Gemini æ¨¡å‹åç¨±
        self.max_retries: int = config.AI_MAX_RETRIES # å¾ AppConfig ç²å–æœ€å¤§é‡è©¦æ¬¡æ•¸
        self.retry_delay: int = config.AI_RETRY_DELAY_SECONDS # å¾ AppConfig ç²å–é‡è©¦å»¶é²ç§’æ•¸
        
        if not self.api_keys:
            logger.error("Google API é‡‘é‘° (GOOGLE_API_KEYS) æœªåœ¨çµ„æ…‹ä¸­è¨­å®šã€‚")
            raise ValueError("Google API é‡‘é‘°æœªè¨­å®šï¼Œç„¡æ³•åˆå§‹åŒ– AsyncGeminiServiceã€‚")
        
        # API é‡‘é‘°è¼ªæ›ç›¸é—œåˆå§‹åŒ–
        self.current_api_key_index: int = 0 # ç”¨æ–¼ API é‡‘é‘°è¼ªæ›çš„ç´¢å¼•
        # æ³¨æ„ï¼šGoogle Gemini SDK é€šå¸¸é€é `genai.configure(api_key="YOUR_API_KEY")` è¨­å®šå…¨åŸŸé‡‘é‘°ã€‚
        # ç‚ºäº†å¯¦ç¾è¼ªæ›ï¼Œæˆ‘å€‘æœƒåœ¨ `_call_gemini_with_rotation` æ–¹æ³•ä¸­å‹•æ…‹è¨­å®šç•¶å‰ä½¿ç”¨çš„é‡‘é‘°ã€‚
        logger.info(f"AsyncGeminiService åˆå§‹åŒ–å®Œæˆï¼Œä½¿ç”¨æ¨¡å‹: {self.model_name}ï¼Œå…± {len(self.api_keys)} å€‹ API é‡‘é‘°ã€‚")

    async def generate_summary_async(self, transcript: str) -> str:
        """
        ç•°æ­¥ç”Ÿæˆæ–‡å­—æ‘˜è¦ï¼Œä¸¦æ ¹æ“šæ–‡æœ¬é•·åº¦æ™ºèƒ½é¸æ“‡ä¸åŒçš„è™•ç†ç­–ç•¥ã€‚

        Args:
            transcript (str): éœ€è¦æ‘˜è¦çš„åŸå§‹è½‰éŒ„æ–‡å­—ã€‚

        Returns:
            str: ç”Ÿæˆçš„æ‘˜è¦æ–‡å­—ã€‚å¦‚æœè™•ç†å¤±æ•—ï¼Œå‰‡è¿”å›ä¸€æ¢å°ä½¿ç”¨è€…å‹å¥½çš„éŒ¯èª¤æˆ–æç¤ºè¨Šæ¯ã€‚
        
        Raises:
            ValueError: å¦‚æœè¼¸å…¥çš„è½‰éŒ„æ–‡å­—ç‚ºç©ºã€‚
        """
        start_time = time.time() # è¨˜éŒ„é–‹å§‹æ™‚é–“ä»¥è¨ˆç®—è™•ç†è€—æ™‚

        try:
            logger.info(f"ğŸ¤– é–‹å§‹ç‚º ID æœªçŸ¥çš„éŒ„éŸ³ç”Ÿæˆ AI æ‘˜è¦ (æ–‡å­—é•·åº¦: {len(transcript)})")
            
            if not transcript or not transcript.strip(): # æª¢æŸ¥æ–‡å­—ç¨¿æ˜¯å¦ç‚ºç©ºæˆ–åƒ…åŒ…å«ç©ºç™½
                logger.warning("ç”Ÿæˆæ‘˜è¦è«‹æ±‚å¤±æ•—ï¼šæä¾›çš„è½‰éŒ„æ–‡å­—ç‚ºç©ºã€‚")
                raise ValueError("è½‰éŒ„æ–‡å­—ç‚ºç©ºï¼Œç„¡æ³•ç”Ÿæˆæ‘˜è¦ã€‚")
            
            text_length = len(transcript)
            logger.info(f"é–‹å§‹è™•ç†æ–‡å­—æ‘˜è¦ï¼Œé•·åº¦: {text_length} å­—å…ƒã€‚")

            # æ ¹æ“šæ–‡æœ¬é•·åº¦é¸æ“‡ä¸åŒçš„æ‘˜è¦ç­–ç•¥
            # TODO: å°‡é•·åº¦é–¾å€¼ (ä¾‹å¦‚ 3000, 7500, 20000) ç§»è‡³ AppConfig ä¸­ä½œç‚ºå¯é…ç½®åƒæ•¸
            estimated_minutes = text_length / 180 # ç²—ç•¥ä¼°ç®—æ¯åˆ†é˜å­—æ•¸ (å¯èª¿æ•´ï¼Œä¾‹å¦‚ 150-250)

            if text_length <= 3000:  # ç´„ 15-20 åˆ†é˜å…§çš„çŸ­éŒ„éŸ³
                logger.info("æ¡ç”¨ã€Œå®Œæ•´æ‘˜è¦ã€ç­–ç•¥è™•ç†çŸ­éŒ„éŸ³ã€‚")
                summary = await self._generate_complete_summary(transcript)
            elif text_length <= 7500: # ç´„ 20-40 åˆ†é˜çš„ä¸­ç­‰éŒ„éŸ³
                logger.info("æ¡ç”¨ã€Œé‡é»æ‘˜è¦ã€ç­–ç•¥è™•ç†ä¸­ç­‰é•·åº¦éŒ„éŸ³ã€‚")
                summary = await self._generate_focused_summary(transcript)
            elif text_length <= 20000: # ç´„ 40-110 åˆ†é˜çš„é•·éŒ„éŸ³
                logger.info("æ¡ç”¨ã€Œçµæ§‹åŒ–æ‘˜è¦ã€ç­–ç•¥è™•ç†é•·éŒ„éŸ³ã€‚")
                summary = await self._generate_structured_summary(transcript)
            else: # è¶…éç´„ 110 åˆ†é˜çš„è¶…é•·éŒ„éŸ³
                logger.info("æ¡ç”¨ã€Œåˆ†æ®µå¼æ‘˜è¦ã€ç­–ç•¥è™•ç†è¶…é•·éŒ„éŸ³ã€‚")
                summary = await self._generate_segmented_summary(transcript, estimated_minutes)
            
            if not summary: # ç¢ºä¿æ‘˜è¦çµæœéç©º
                logger.error("AI æ‘˜è¦ç”Ÿæˆå¾Œè¿”å›çµæœç‚ºç©ºã€‚")
                # å³ä½¿ _extract_response_text æ‡‰è™•ç†æ­¤æƒ…æ³ï¼Œå¤šä¸€å±¤é˜²è­·
                raise Exception("æ‘˜è¦ç”Ÿæˆå¤±æ•—ï¼Œè¿”å›çµæœç‚ºç©ºã€‚") 
            
            processing_time = time.time() - start_time
            logger.info(f"âœ¨ AI æ‘˜è¦ç”ŸæˆæˆåŠŸå®Œæˆï¼Œè€—æ™‚: {processing_time:.2f} ç§’ã€‚æ‘˜è¦é•·åº¦: {len(summary)} å­—å…ƒã€‚")
            return summary
            
        except ValueError as ve: # æ•ç²ç‰¹å®šçš„ ValueError (ä¾‹å¦‚ç©ºçš„ transcript)
            logger.error(f"ç”Ÿæˆæ‘˜è¦æ™‚ç™¼ç”Ÿæ•¸å€¼éŒ¯èª¤: {str(ve)}", exc_info=True)
            return f"æ‘˜è¦ç”Ÿæˆå¤±æ•—ï¼šè¼¸å…¥å…§å®¹ä¸æ­£ç¢º ({str(ve)})"
        except Exception as e: # æ•ç²æ‰€æœ‰å…¶ä»–åœ¨æ‘˜è¦æµç¨‹ä¸­ç™¼ç”Ÿçš„ä¾‹å¤–
            processing_time = time.time() - start_time # è¨ˆç®—éŒ¯èª¤æ™‚çš„è™•ç†æ™‚é–“
            logger.error(f"âŒ ç”Ÿæˆ AI æ‘˜è¦éç¨‹ä¸­ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤ (è€—æ™‚ {processing_time:.2f} ç§’): {str(e)}", exc_info=True)
            return "æŠ±æ­‰ï¼ŒAI æ‘˜è¦åŠŸèƒ½æš«æ™‚é‡åˆ°å•é¡Œã€‚æ‚¨çš„æ–‡å­—ç¨¿æ‡‰å·²ä¿å­˜ï¼Œè«‹ç¨å¾Œå†è©¦æˆ–è¯ç¹«æŠ€è¡“æ”¯æ´ã€‚"

    async def _generate_complete_summary(self, text: str) -> str:
        """
        ç‚ºçŸ­æ–‡æœ¬ (é€šå¸¸ <= 3000 å­—å…ƒ) ç”Ÿæˆè¼ƒç‚ºå®Œæ•´çš„æ‘˜è¦ã€‚

        Args:
            text (str): éœ€è¦æ‘˜è¦çš„æ–‡æœ¬ã€‚

        Returns:
            str: ç”Ÿæˆçš„å®Œæ•´æ‘˜è¦ã€‚
        """
        logger.debug(f"åŸ·è¡Œã€Œå®Œæ•´æ‘˜è¦ã€é‡å°é•·åº¦ç‚º {len(text)} çš„æ–‡æœ¬ã€‚")
        prompt = self._build_summary_prompt(text, summary_type="å®Œæ•´æ‘˜è¦")
        
        generation_config = genai_types.GenerationConfig( # ä½¿ç”¨ genai_types.GenerationConfig
            temperature=0.2, # ç¨å¾®æé«˜ä¸€é»æº«åº¦ä»¥ç²å¾—æ›´å¤šæ¨£æ€§ï¼Œä½†ä»ä¿æŒäº‹å¯¦æ€§
            max_output_tokens=8192, # ç¢ºä¿æœ‰è¶³å¤ ç©ºé–“è¼¸å‡ºå®Œæ•´æ‘˜è¦ (Gemini Flash æœ€å¤§åˆ° 8192)
            top_p=0.9, # top_p æ§åˆ¶å¤šæ¨£æ€§
            top_k=20  # top_k æ§åˆ¶å¤šæ¨£æ€§
        )
        
        response = await self._call_gemini_with_rotation(prompt, generation_config)
        return self._extract_response_text(response, original_text=text, summary_type_for_log="å®Œæ•´æ‘˜è¦")
    
    async def _generate_focused_summary(self, text: str) -> str:
        """
        ç‚ºä¸­ç­‰é•·åº¦æ–‡æœ¬ (é€šå¸¸ > 3000 ä¸” <= 7500 å­—å…ƒ) ç”Ÿæˆé‡é»æ‘˜è¦ã€‚
        å¦‚æœæ¨™æº–æ–¹æ³•å¤±æ•—ï¼Œæœƒå˜—è©¦ä½¿ç”¨ç°¡åŒ–ç‰ˆæœ¬ã€‚

        Args:
            text (str): éœ€è¦æ‘˜è¦çš„æ–‡æœ¬ã€‚

        Returns:
            str: ç”Ÿæˆçš„é‡é»æ‘˜è¦ã€‚
        """
        try:
            logger.info(f"åŸ·è¡Œã€Œé‡é»æ‘˜è¦ã€é‡å°é•·åº¦ç‚º {len(text)} çš„æ–‡æœ¬ã€‚")
            prompt = self._build_summary_prompt(text, summary_type="é‡é»æ‘˜è¦")
            
            generation_config = genai_types.GenerationConfig(
                temperature=0.25, # ä¸­ç­‰é•·åº¦ï¼Œå¯ä»¥ç¨å¾®æ›´æœ‰å½ˆæ€§
                max_output_tokens=8192,
                top_p=0.85,
                top_k=30
            )
            
            response = await self._call_gemini_with_rotation(prompt, generation_config)
            result = self._extract_response_text(response, original_text=text, summary_type_for_log="é‡é»æ‘˜è¦")
            
            logger.info(f"ã€Œé‡é»æ‘˜è¦ã€ç”ŸæˆæˆåŠŸï¼Œæ‘˜è¦é•·åº¦: {len(result)} å­—å…ƒã€‚")
            return result
            
        except Exception as e:
            logger.error(f"ã€Œé‡é»æ‘˜è¦ã€åˆæ­¥å˜—è©¦å¤±æ•—: {str(e)}ã€‚å˜—è©¦ä½¿ç”¨ç°¡åŒ–ç‰ˆé‡é»æ‘˜è¦ã€‚", exc_info=True)
            return await self._generate_simple_focused_summary(text) # å‚™ç”¨æ–¹æ¡ˆ
    
    async def _generate_structured_summary(self, text: str) -> str:
        """
        ç‚ºé•·æ–‡æœ¬ (é€šå¸¸ > 7500 ä¸” <= 20000 å­—å…ƒ) ç”Ÿæˆçµæ§‹åŒ–æ‘˜è¦ã€‚
        å°‡æ–‡æœ¬åˆ†æˆä¸‰éƒ¨åˆ†é è¦½ï¼Œä¸¦è¦æ±‚ AI æä¾›åŒ…å«ä¸»è¦è­°é¡Œã€é‡é»å…§å®¹ã€çµè«–å’Œé—œéµå­—çš„çµæ§‹åŒ–è¼¸å‡ºã€‚

        Args:
            text (str): éœ€è¦æ‘˜è¦çš„æ–‡æœ¬ã€‚

        Returns:
            str: ç”Ÿæˆçš„çµæ§‹åŒ–æ‘˜è¦ï¼ŒåŒ…å«éŒ„éŸ³æ™‚é•·ä¼°ç®—ã€‚
        """
        logger.info(f"åŸ·è¡Œã€Œçµæ§‹åŒ–æ‘˜è¦ã€é‡å°é•·åº¦ç‚º {len(text)} çš„æ–‡æœ¬ã€‚")
        # é è¦½æ–‡æœ¬çš„å‰ã€ä¸­ã€å¾Œéƒ¨åˆ†ï¼Œæ¯éƒ¨åˆ†æœ€å¤š2000å­—å…ƒï¼Œä»¥ç¬¦åˆ Gemini API çš„ä¸Šä¸‹æ–‡é•·åº¦é™åˆ¶å’Œæˆæœ¬æ•ˆç›Š
        preview_length = 2000 
        length = len(text)
        segment1_preview = text[:preview_length]
        segment2_preview = text[length//2 - preview_length//2 : length//2 + preview_length//2] if length > preview_length * 2 else ""
        segment3_preview = text[-preview_length:] if length > preview_length else "" # å¦‚æœæ–‡æœ¬æœ¬èº«å°æ–¼ preview_lengthï¼Œå‰‡ segment3_preview æœƒæ˜¯é‡è¤‡çš„

        prompt = f"""è«‹åˆ†æä»¥ä¸‹è¼ƒé•·éŒ„éŸ³çš„å…§å®¹ï¼Œä¸¦æä¾›ä¸€å€‹è©³ç´°ä¸”çµæ§‹åŒ–çš„æ‘˜è¦ã€‚
éŒ„éŸ³å…§å®¹é è¦½å¦‚ä¸‹ï¼ˆå¯èƒ½åƒ…ç‚ºéƒ¨åˆ†ï¼‰ï¼š

ã€éŒ„éŸ³é–‹é ­ç‰‡æ®µã€‘
{segment1_preview}
...
ã€éŒ„éŸ³ä¸­é–“ç‰‡æ®µã€‘
{segment2_preview if segment2_preview else "(ä¸­é–“ç‰‡æ®µçœç•¥æˆ–èˆ‡é–‹é ­/çµå°¾é‡ç–Š)"}
...
ã€éŒ„éŸ³çµå°¾ç‰‡æ®µã€‘
{segment3_preview if segment3_preview else "(çµå°¾ç‰‡æ®µçœç•¥æˆ–èˆ‡é–‹é ­é‡ç–Š)"}

**æ‚¨çš„ä»»å‹™æ˜¯åŸºæ–¼å°ã€å®Œæ•´éŒ„éŸ³æ–‡æœ¬ã€‘ï¼ˆå„˜ç®¡æ­¤è™•åƒ…å±•ç¤ºç‰‡æ®µï¼‰çš„ç†è§£ï¼Œä¾†å®Œæˆä»¥ä¸‹çµæ§‹åŒ–æ‘˜è¦ã€‚**

è«‹åš´æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼æä¾›è©³ç´°çš„æ‘˜è¦ï¼š

## ğŸ“ æœƒè­°/å°è©±æ‘˜è¦å ±å‘Š

### ğŸ¯ ä¸»è¦è­°é¡Œèˆ‡ç›®çš„ (è«‹æ¢åˆ—3-5å€‹æ ¸å¿ƒè¨è«–é»æˆ–æœƒè­°ç›®çš„ï¼Œæ¯å€‹è­°é¡Œå¾Œéœ€æœ‰2-3å¥çš„è©³ç´°é—¡è¿°ï¼Œèªªæ˜å…¶é‡è¦æ€§æˆ–èƒŒæ™¯)
- [è­°é¡Œä¸€ï¼šè©³ç´°é—¡è¿°...]
- [è­°é¡ŒäºŒï¼šè©³ç´°é—¡è¿°...]

### ğŸ“‹ è©³ç´°å…§å®¹èˆ‡è¨è«–è¦é» (è«‹æ·±å…¥èªªæ˜è¨è«–ä¸­çš„é‡è¦è§€é»ã€è«–æ“šã€æ•¸æ“šæ”¯æŒã€æ¡ˆä¾‹åˆ†ææˆ–é—œéµæ±ºç­–éç¨‹ï¼Œè‡³å°‘5-8å€‹é—œéµé»ï¼Œæ¯é»éœ€æœ‰è¶³å¤ ä¸Šä¸‹æ–‡å’Œç´°ç¯€æ”¯æ’)
- [å…§å®¹é»ä¸€ï¼šè©³ç´°èªªæ˜èˆ‡ç´°ç¯€...]
- [å…§å®¹é»äºŒï¼šè©³ç´°èªªæ˜èˆ‡ç´°ç¯€...]

### âœ… è¡Œå‹•é …ç›®èˆ‡æ±ºç­– (å¦‚æœ‰ï¼Œè«‹åˆ—å‡ºæ˜ç¢ºçš„å¾…è¾¦äº‹é …ã€å·²é”æˆçš„æ±ºç­–ã€è² è²¬äººåŠé è¨ˆå®Œæˆæ™‚é–“æˆ–å¾ŒçºŒæ­¥é©Ÿ)
- [è¡Œå‹•é …/æ±ºç­–ä¸€ï¼š(è² è²¬äººï¼šXXX) (é è¨ˆå®Œæˆ/ç‹€æ…‹ï¼šYYYY-MM-DD æˆ– å·²å®Œæˆ) èªªæ˜...]

### ğŸ’¡ é—œéµæ´å¯Ÿèˆ‡çµè«– (è«‹ç¸½çµè‡³å°‘3-5å€‹å¾è¨è«–ä¸­ç²å¾—çš„æœ€é‡è¦è¦‹è§£ã€æ·±å±¤çµè«–æˆ–åæ€ï¼Œä¸¦ç°¡è¿°å…¶æ¨å°ä¾æ“šæˆ–å°æœªä¾†çš„å½±éŸ¿)
- [æ´å¯Ÿä¸€ï¼š(æ¨å°ä¾æ“šæˆ–å½±éŸ¿ï¼š...) çµè«–èªªæ˜...]

### ğŸ”‘ æ ¸å¿ƒé—œéµå­— (è«‹æå–è‡³å°‘10-15å€‹èˆ‡å…§å®¹é«˜åº¦ç›¸é—œçš„æ ¸å¿ƒé—œéµå­—æˆ–é—œéµçŸ­èªï¼Œç”¨é€—è™Ÿåˆ†éš”)
[é—œéµå­—1, é—œéµå­—2, é—œéµå­—3, ...]

è«‹å‹™å¿…ä½¿ç”¨ã€ç¹é«”ä¸­æ–‡ã€‘å›æ‡‰ã€‚å…§å®¹å¿…é ˆè©³ç´°ã€ç²¾ç¢ºä¸”å…·æœ‰è‰¯å¥½çš„çµ„ç¹”æ€§ã€‚è«‹ç¢ºä¿æ‘˜è¦èƒ½å¤ å……åˆ†åæ˜ åŸå§‹éŒ„éŸ³çš„è¤‡é›œæ€§å’Œæ·±åº¦ã€‚
"""

        generation_config = genai_types.GenerationConfig(
            temperature=0.3, # çµæ§‹åŒ–è¼¸å‡ºï¼Œæº«åº¦å¯ä»¥ç¨é«˜ä¸€é»ä»¥ç²å¾—æ›´è‡ªç„¶çš„èªè¨€
            max_output_tokens=8192,
            top_p=0.85,
            top_k=35
        )
        
        response = await self._call_gemini_with_rotation(prompt, generation_config)
        result = self._extract_response_text(response, original_text=text, is_structured_summary=True, summary_type_for_log="çµæ§‹åŒ–æ‘˜è¦")
        
        estimated_minutes_display = len(text) / 180 
        logger.info(f"ã€Œçµæ§‹åŒ–æ‘˜è¦ã€ç”ŸæˆæˆåŠŸï¼Œæ‘˜è¦é•·åº¦: {len(result)} å­—å…ƒã€‚")
        return f"{result}\n\nğŸ“Š éŒ„éŸ³æ™‚é•·ä¼°ç®—ï¼šç´„ {estimated_minutes_display:.0f} åˆ†é˜"
    
    async def _generate_segmented_summary(self, text: str, estimated_minutes: float) -> str:
        """
        ç‚ºè¶…é•·æ–‡æœ¬ (é€šå¸¸ > 20000 å­—å…ƒ) ç”Ÿæˆåˆ†æ®µå¼æ‘˜è¦ã€‚
        æ­¤æ–¹æ³•æœƒå°‡æ–‡æœ¬åˆ†å‰²æˆå¤šå€‹æ®µè½ï¼Œå°é¸å–çš„é—œéµæ®µè½åˆ†åˆ¥ç”Ÿæˆæ‘˜è¦ï¼Œç„¶å¾Œå†å°é€™äº›åˆ†æ®µæ‘˜è¦é€²è¡Œç¸½çµã€‚

        Args:
            text (str): éœ€è¦æ‘˜è¦çš„è¶…é•·æ–‡æœ¬ã€‚
            estimated_minutes (float): é ä¼°çš„éŒ„éŸ³æ™‚é•· (åˆ†é˜)ï¼Œç”¨æ–¼æ—¥èªŒå’Œæœ€çµ‚è¼¸å‡ºã€‚

        Returns:
            str: ç”Ÿæˆçš„åˆ†æ®µå¼æ‘˜è¦ï¼ŒåŒ…å«æ•´é«”æ‘˜è¦ã€åˆ†æ®µé‡é»ã€æ™‚é•·ä¼°ç®—å’Œåˆ†æèªªæ˜ã€‚
        """
        logger.info(f"åŸ·è¡Œã€Œåˆ†æ®µå¼æ‘˜è¦ã€é‡å°é•·åº¦ç‚º {len(text)} çš„æ–‡æœ¬ (é ä¼° {estimated_minutes:.0f} åˆ†é˜)ã€‚")
        try:
            segments = [] # å­˜å„²æ–‡æœ¬ç‰‡æ®µ
            # è€ƒæ…®åˆ° Gemini API çš„ä¸Šä¸‹æ–‡è¦–çª—å’Œæˆæœ¬æ•ˆç›Šï¼Œæ¯æ®µç´„ 2500-3000 å­—å…ƒè¼ƒç‚ºåˆé©
            chunk_size = getattr(self.config, 'SEGMENT_CHUNK_SIZE', 2800) 
            for i in range(0, len(text), chunk_size):
                segment = text[i:i+chunk_size]
                segments.append(segment)
            
            logger.info(f"è¶…é•·éŒ„éŸ³å·²åˆ†å‰²ç‚º {len(segments)} æ®µé€²è¡Œè™•ç†ã€‚")
            
            # æ ¹æ“šçµ„æ…‹æ±ºå®šåˆ†æå“ªäº›æ®µè½ä»¥åŠå¤šå°‘æ®µè½
            full_analysis = getattr(self.config, 'FULL_ANALYSIS_SEGMENTED', False) # æ˜¯å¦å°æ‰€æœ‰é¸å®šæ®µè½é€²è¡Œå®Œæ•´åˆ†æ
            max_segments_to_analyze = getattr(self.config, 'MAX_SEGMENTS_FOR_SEGMENTED_SUMMARY', 7) # é è¨­æœ€å¤šè™•ç†7å€‹é¸å–æ®µè½
            
            if full_analysis and len(segments) > max_segments_to_analyze * 1.5 : # å¦‚æœæ®µè½æ•¸é è¶…é™åˆ¶ï¼Œå³ä½¿æ˜¯å®Œæ•´åˆ†ææ¨¡å¼ä¹Ÿæç¤º
                 logger.warning(f"å³ä½¿åœ¨å®Œæ•´åˆ†ææ¨¡å¼ä¸‹ï¼Œæ®µè½æ•¸ ({len(segments)}) ä¹Ÿé è¶…å»ºè­°è™•ç†ä¸Šé™ ({max_segments_to_analyze})ï¼Œå¯èƒ½å°è‡´è™•ç†æ™‚é–“éé•·æˆ–æˆæœ¬è¼ƒé«˜ã€‚")

            # æ™ºèƒ½é¸å–æˆ–é™åˆ¶æ®µè½æ•¸é‡
            if len(segments) <= max_segments_to_analyze: # å¦‚æœç¸½æ®µè½æ•¸åœ¨é™åˆ¶å…§ï¼Œå‰‡å…¨éƒ¨è™•ç†
                key_segments_indices = list(range(len(segments)))
                analysis_note = f"ï¼ˆå·²åˆ†æå…¨éƒ¨ {len(segments)} æ®µï¼‰"
            elif not full_analysis: # éå®Œæ•´åˆ†ææ¨¡å¼ä¸‹çš„æ™ºèƒ½é¸å–
                # ç­–ç•¥ï¼šé¸å–é–‹é ­ã€ä¸­é–“ã€çµå°¾çš„æ®µè½ï¼Œç¢ºä¿è¦†è“‹æ€§
                num_start = min(3, len(segments)) # é–‹é ­æœ€å¤š3æ®µ
                num_end = min(3, len(segments) - num_start) # çµå°¾æœ€å¤š3æ®µ
                num_middle = max(0, max_segments_to_analyze - num_start - num_end) # ä¸­é–“æ®µè½å¡«è£œå‰©é¤˜åé¡

                key_segments_indices = list(range(num_start)) # é–‹é ­æ®µè½ç´¢å¼•
                
                if num_middle > 0 and len(segments) > num_start + num_end: # ç¢ºä¿æœ‰è¶³å¤ æ®µè½é¸å–ä¸­é–“éƒ¨åˆ†
                    middle_step = (len(segments) - num_start - num_end) // (num_middle + 1)
                    for i in range(num_middle):
                        key_segments_indices.append(num_start + (i + 1) * middle_step)
                
                if num_end > 0 : # çµå°¾æ®µè½ç´¢å¼•
                     key_segments_indices.extend(list(range(len(segments) - num_end, len(segments))))
                
                key_segments_indices = sorted(list(set(key_segments_indices))) # å»é‡ä¸¦æ’åº
                analysis_note = f"ï¼ˆæ™ºèƒ½é¸å–ï¼šå¾ {len(segments)} æ®µä¸­é¸å– {len(key_segments_indices)} å€‹é—œéµæ®µè½é€²è¡Œåˆ†æï¼‰"
            else: # å®Œæ•´åˆ†ææ¨¡å¼ï¼Œä½†è¶…å‡ºæœ€å¤§é™åˆ¶
                key_segments_indices = list(range(max_segments_to_analyze))
                analysis_note = f"ï¼ˆå› æ®µè½éå¤šï¼Œå·²åˆ†æå‰ {max_segments_to_analyze} æ®µï¼Œç¸½å…± {len(segments)} æ®µï¼‰"

            key_segments = [segments[i] for i in key_segments_indices]
            logger.info(f"å°‡å° {len(key_segments)} å€‹é¸å®šæ®µè½é€²è¡Œæ‘˜è¦ã€‚åˆ†æèªªæ˜: {analysis_note}")

            segment_summaries = []
            total_selected_segments = len(key_segments)
            segment_processing_delay = getattr(self.config, 'SEGMENT_PROCESSING_DELAY', 0.6) # ç²å–æˆ–è¨­å®šæ®µè½è™•ç†å»¶é²

            if total_selected_segments > 10: # å¦‚æœé¸å®šæ®µè½è¼ƒå¤šï¼Œæç¤ºé æœŸæ™‚é–“
                 logger.info(f"é–‹å§‹åˆ†æ {total_selected_segments} å€‹é¸å®šæ®µè½ï¼Œé è¨ˆéœ€è¦ç´„ {total_selected_segments * segment_processing_delay * 2:.0f} ç§’ (åŒ…å«APIèª¿ç”¨å’Œå»¶é²)ã€‚")
            
            for i, segment_text in enumerate(key_segments):
                original_segment_index = key_segments_indices[i] # ç²å–æ­¤ç‰‡æ®µåœ¨åŸå§‹ segments åˆ—è¡¨ä¸­çš„ç´¢å¼•
                segment_label = f"åŸå§‹ç¬¬ {original_segment_index + 1} æ®µ" # ä½¿ç”¨åŸå§‹æ®µè½ç·¨è™Ÿ
                
                try:
                    # æç¤ºè©è¦æ±‚å°å–®å€‹ç‰‡æ®µé€²è¡Œç°¡æ½”ç¸½çµ
                    prompt = f"è«‹é‡å°ä»¥ä¸‹ã€éŒ„éŸ³ç‰‡æ®µã€‘({segment_label})ï¼Œç”¨ç¹é«”ä¸­æ–‡æç…‰å‡ºå…¶æ ¸å¿ƒè¦é»å’Œé—œéµè³‡è¨Šï¼ˆç´„100-200å­—ï¼‰ï¼š\n\n---\n{segment_text[:3000]}\n---\n\næ ¸å¿ƒè¦é»èˆ‡é—œéµè³‡è¨Šï¼š" # é™åˆ¶é è¦½é•·åº¦
                    
                    generation_config_segment = genai_types.GenerationConfig(
                        temperature=0.15, # ç¨é«˜æº«åº¦ä»¥ç²å–æ›´è‡ªç„¶çš„ç‰‡æ®µæ‘˜è¦
                        max_output_tokens=2048, # è¶³å¤ ç‰‡æ®µæ‘˜è¦
                        top_p=0.8,
                        top_k=15
                    )
                    
                    response = await self._call_gemini_with_rotation(prompt, generation_config_segment)
                    # å‡è¨­ _extract_response_text å·²è¢«æ›´æ–°ä»¥è™•ç† is_structured_summary å’Œ summary_type_for_log
                    summary_text = self._extract_response_text(response, original_text=segment_text, summary_type_for_log=f"ç‰‡æ®µ {segment_label}")
                    if summary_text: # ç¢ºä¿æå–åˆ°æ–‡æœ¬
                        segment_summaries.append(f"ã€{segment_label}ç¸½çµã€‘\n{summary_text}")
                    else:
                        segment_summaries.append(f"ã€{segment_label}ç¸½çµã€‘\n(æ­¤ç‰‡æ®µæœªèƒ½ç”Ÿæˆæœ‰æ•ˆæ‘˜è¦)")
                        logger.warning(f"éŒ„éŸ³ç‰‡æ®µ {segment_label} æœªèƒ½ç”Ÿæˆæœ‰æ•ˆæ‘˜è¦æ–‡æœ¬ã€‚")

                    if (i + 1) % 5 == 0 or (i + 1) == total_selected_segments: # æ¯5æ®µæˆ–æœ€å¾Œä¸€æ®µæ™‚è¨˜éŒ„é€²åº¦
                        logger.info(f"åˆ†æ®µæ‘˜è¦é€²åº¦ï¼šå·²å®Œæˆ {i + 1}/{total_selected_segments} å€‹é¸å®šæ®µè½çš„åˆ†æã€‚")
                    
                    if i < total_selected_segments - 1: # ä¸æ˜¯æœ€å¾Œä¸€å€‹ç‰‡æ®µæ™‚æ‰å»¶é²
                        await asyncio.sleep(segment_processing_delay) 
                    
                except Exception as e_segment:
                    logger.warning(f"è™•ç†éŒ„éŸ³ç‰‡æ®µ {segment_label} æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e_segment)}", exc_info=True)
                    segment_summaries.append(f"ã€{segment_label}ç¸½çµã€‘\n(è™•ç†æ­¤ç‰‡æ®µæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼Œå·²è·³é)")
            
            combined_segment_summaries = "\n\n---\n\n".join(segment_summaries) # ä½¿ç”¨åˆ†éš”ç¬¦çµ„åˆå„ç‰‡æ®µæ‘˜è¦
            
            # åŸºæ–¼æ‰€æœ‰ç‰‡æ®µæ‘˜è¦ï¼Œç”Ÿæˆæœ€çµ‚çš„æ•´é«”æ‘˜è¦
            final_summary_prompt = f"""ä»¥ä¸‹æ˜¯å¾ä¸€ä»½é•·ç¯‡éŒ„éŸ³ä¸­æå–ä¸¦åˆ†åˆ¥ç¸½çµçš„ã€å¤šå€‹ç‰‡æ®µæ‘˜è¦ã€‘ã€‚è«‹åŸºæ–¼é€™äº›ç‰‡æ®µæ‘˜è¦ï¼Œæ•´åˆä¸¦ç”Ÿæˆä¸€ä»½é€£è²«ã€å…¨é¢çš„ã€æ•´é«”æ‘˜è¦å ±å‘Šã€‘ã€‚

ã€å„ç‰‡æ®µæ‘˜è¦å½™ç¸½ã€‘:
{combined_segment_summaries}

**æ‚¨çš„ä»»å‹™æ˜¯å®Œæˆä»¥ä¸‹ã€æ•´é«”æ‘˜è¦å ±å‘Šã€‘çš„å„å€‹éƒ¨åˆ†ï¼Œç¢ºä¿å…§å®¹çš„æº–ç¢ºæ€§ã€å®Œæ•´æ€§å’Œé‚è¼¯æ€§ï¼š**

## ğŸ“ æ•´é«”æ‘˜è¦å ±å‘Š

### ğŸ¯ ä¸»è¦è­°é¡Œèˆ‡æ ¸å¿ƒç›®çš„ (è«‹ç¶œåˆæ‰€æœ‰ç‰‡æ®µï¼Œæç…‰å‡º3-5å€‹è²«ç©¿å…¨æ–‡çš„æ ¸å¿ƒè­°é¡Œæˆ–å°è©±çš„ä¸»è¦ç›®çš„ï¼Œä¸¦ç°¡è¿°å…¶é‡è¦æ€§)
- [æ ¸å¿ƒè­°é¡Œä¸€ï¼šé‡è¦æ€§ç°¡è¿°...]
- [æ ¸å¿ƒè­°é¡ŒäºŒï¼šé‡è¦æ€§ç°¡è¿°...]

### ğŸ“‹ é—œéµå…§å®¹èˆ‡é‡è¦ç´°ç¯€ (è«‹æ•´åˆå„ç‰‡æ®µçš„é—œéµè³‡è¨Šï¼ŒæŒ‰ä¸»é¡Œæˆ–é‚è¼¯é †åºæ­¸ç´ï¼Œæä¾›è‡³å°‘5-8å€‹é‡è¦å…§å®¹é»ï¼Œä¸¦è£œå……å¿…è¦çš„ä¸Šä¸‹æ–‡æˆ–ç´°ç¯€)
- [é‡è¦å…§å®¹é»ä¸€ï¼šè©³ç´°èªªæ˜...]
- [é‡è¦å…§å®¹é»äºŒï¼šè©³ç´°èªªæ˜...]

### âœ… ä¸»è¦æ±ºç­–èˆ‡è¡Œå‹•é …ç›® (å¦‚æœ‰ï¼Œè«‹æ˜ç¢ºåˆ—å‡ºè¨è«–ä¸­é”æˆçš„é—œéµæ±ºç­–æˆ–éœ€è¦æ¡å–çš„å…·é«”è¡Œå‹•ï¼ŒåŒ…æ‹¬å¯èƒ½çš„è² è²¬äººå’Œæ™‚ç¨‹)
- [æ±ºç­–/è¡Œå‹•ä¸€ï¼š(è² è²¬äºº/æ™‚ç¨‹ï¼š...) èªªæ˜...]

### ğŸ’¡ ç¶œåˆè¦‹è§£èˆ‡æ·±å±¤çµè«– (è«‹åŸºæ–¼æ‰€æœ‰ç‰‡æ®µçš„åˆ†æï¼Œæå‡ºè‡³å°‘3å€‹å…·æœ‰æ´å¯ŸåŠ›çš„ç¶œåˆè¦‹è§£æˆ–æ·±å±¤çµè«–ï¼Œä¸¦èªªæ˜å…¶æ¨æ–·ä¾æ“šæˆ–æ½›åœ¨å½±éŸ¿)
- [ç¶œåˆè¦‹è§£ä¸€ï¼š(ä¾æ“š/å½±éŸ¿ï¼š...) çµè«–èªªæ˜...]

### ğŸ”‘ å…¨æ–‡æ ¸å¿ƒé—œéµå­— (è«‹æå–10-15å€‹èƒ½å¤ ä»£è¡¨æ•´å€‹éŒ„éŸ³å…§å®¹çš„æ ¸å¿ƒé—œéµå­—æˆ–çŸ­èªï¼Œç”¨é€—è™Ÿåˆ†éš”)
[é—œéµå­—1, é—œéµå­—2, ...]

è«‹å‹™å¿…ä½¿ç”¨ã€ç¹é«”ä¸­æ–‡ã€‘é€²è¡Œå›æ‡‰ã€‚å ±å‘Šæ‡‰çµæ§‹æ¸…æ™°ã€å…§å®¹è©³å¯¦ï¼Œèƒ½å¤ è®“è®€è€…å¿«é€ŸæŒæ¡é•·ç¯‡éŒ„éŸ³çš„æ•´é«”æƒ…æ³å’Œæ ¸å¿ƒåƒ¹å€¼ã€‚
"""

            final_generation_config = genai_types.GenerationConfig(
                temperature=0.3,
                max_output_tokens=8192,
                top_p=0.85,
                top_k=40
            )
            
            final_response = await self._call_gemini_with_rotation(final_summary_prompt, final_generation_config)
            final_overall_summary = self._extract_response_text(final_response, original_text=combined_segment_summaries, is_structured_summary=True, summary_type_for_log="åˆ†æ®µå¾Œæ•´é«”æ‘˜è¦")
            
            # çµ„åˆæœ€çµ‚çµæœ
            result = f"âœ¨ **æ•´é«”æ‘˜è¦å ±å‘Š** âœ¨\n{final_overall_summary}\n\n---\n\nğŸ” **å„ç‰‡æ®µé‡é»å›é¡§** ğŸ”\n{combined_segment_summaries}\n\n---\n"
            result += f"â±ï¸ **éŒ„éŸ³è³‡è¨Š**ï¼šç¸½æ™‚é•·ç´„ {estimated_minutes:.0f} åˆ†é˜ (åŸå§‹æ–‡æœ¬ç´„ {len(text)} å­—)ã€‚\n"
            result += f"ğŸ“Š **åˆ†ææ–¹å¼**ï¼š{analysis_note}"
            
            logger.info(f"ã€Œåˆ†æ®µå¼æ‘˜è¦ã€ç”ŸæˆæˆåŠŸï¼Œæ•´é«”æ‘˜è¦é•·åº¦: {len(final_overall_summary)}ï¼Œåˆ†æ®µé‡é»ç¸½é•·åº¦: {len(combined_segment_summaries)}ã€‚")
            return result
            
        except Exception as e:
            logger.error(f"ã€Œåˆ†æ®µå¼æ‘˜è¦ã€è™•ç†éç¨‹ä¸­ç™¼ç”Ÿåš´é‡éŒ¯èª¤: {str(e)}ã€‚å˜—è©¦ä½¿ç”¨å‚™ç”¨æ‘˜è¦æ–¹æ³•ã€‚", exc_info=True)
            return await self._generate_fallback_summary(text, estimated_minutes) # å‚™ç”¨æ–¹æ¡ˆ
    
    async def _generate_fallback_summary(self, text: str, estimated_minutes: float) -> str:
        """
        å‚™ç”¨æ‘˜è¦ç”Ÿæˆæ–¹æ³• (ç•¶ä¸»è¦çš„åˆ†æ®µè™•ç†å¤±æ•—æ™‚èª¿ç”¨)ã€‚
        æ­¤æ–¹æ³•åƒ…è™•ç†æ–‡æœ¬çš„é–‹é ­å’Œçµå°¾éƒ¨åˆ†ä»¥ç”Ÿæˆä¸€å€‹éå¸¸ç°¡ç•¥çš„æ‘˜è¦ã€‚

        Args:
            text (str): åŸå§‹æ–‡æœ¬ã€‚
            estimated_minutes (float): é ä¼°çš„éŒ„éŸ³æ™‚é•·ã€‚

        Returns:
            str: ç”Ÿæˆçš„å‚™ç”¨æ‘˜è¦æˆ–é€²ä¸€æ­¥çš„éŒ¯èª¤æç¤ºã€‚
        """
        logger.info(f"åŸ·è¡Œã€Œå‚™ç”¨æ‘˜è¦ã€é‡å°é•·åº¦ç‚º {len(text)} çš„æ–‡æœ¬ (é ä¼° {estimated_minutes:.0f} åˆ†é˜)ã€‚")
        # åªå–é–‹é ­å’Œçµå°¾é€²è¡Œæ‘˜è¦ï¼Œé è¦½é•·åº¦å¯èª¿æ•´
        preview_length_fallback = 2000 
        start_text_preview = text[:preview_length_fallback]
        end_text_preview = text[-preview_length_fallback:] if len(text) > preview_length_fallback * 2 else ""
        
        summary_input_text = f"éŒ„éŸ³é–‹é ­ç‰‡æ®µï¼š\n{start_text_preview}"
        if end_text_preview:
            summary_input_text += f"\n\néŒ„éŸ³çµå°¾ç‰‡æ®µï¼š\n{end_text_preview}"
        
        prompt = f"é€™æ˜¯ä¸€ä»½é•·ç´„ {estimated_minutes:.0f} åˆ†é˜çš„éŒ„éŸ³ï¼Œç”±æ–¼å…§å®¹éé•·æˆ–è™•ç†è¤‡é›œï¼Œç›®å‰åƒ…èƒ½æä¾›åŸºæ–¼å…¶é–‹é ­å’Œçµå°¾ç‰‡æ®µçš„ã€ç²¾ç°¡æ‘˜è¦ã€‘ã€‚è«‹æ ¹æ“šä»¥ä¸‹æä¾›çš„ç‰‡æ®µå…§å®¹ï¼Œç”¨ç¹é«”ä¸­æ–‡ç¸½çµå‡ºæœ€é‡è¦çš„æ ¸å¿ƒè³‡è¨Šï¼š\n\n{summary_input_text}"
        
        try:
            generation_config = genai_types.GenerationConfig(
                temperature=0.2,
                max_output_tokens=4096, # é™åˆ¶è¼¸å‡ºä»¥ç¬¦åˆå‚™ç”¨æ€§è³ª
                top_p=0.8,
                top_k=20
            )
            
            response = await self._call_gemini_with_rotation(prompt, generation_config)
            result_text = self._extract_response_text(response, original_text=summary_input_text, summary_type_for_log="å‚™ç”¨æ‘˜è¦")
            
            logger.info(f"ã€Œå‚™ç”¨æ‘˜è¦ã€ç”ŸæˆæˆåŠŸï¼Œæ‘˜è¦é•·åº¦: {len(result_text)}ã€‚")
            return f"## âš ï¸ ç²¾ç°¡æ‘˜è¦ (å‚™ç”¨æ–¹æ¡ˆ)\n\n{result_text}\n\n**è«‹æ³¨æ„**ï¼šç”±æ–¼åŸå§‹éŒ„éŸ³å…§å®¹éé•·æˆ–å…ˆå‰è™•ç†é‡åˆ°å›°é›£ï¼Œæ­¤ç‚ºåŸºæ–¼éƒ¨åˆ†å…§å®¹ç”Ÿæˆçš„ç²¾ç°¡æ‘˜è¦ã€‚\n\nâ±ï¸ éŒ„éŸ³ç¸½æ™‚é•·ç´„ {estimated_minutes:.0f} åˆ†é˜ã€‚"
            
        except Exception as e_fallback:
            logger.error(f"ã€Œå‚™ç”¨æ‘˜è¦ã€ç”Ÿæˆä¹Ÿå¤±æ•—: {str(e_fallback)}", exc_info=True)
            # åœ¨æ‰€æœ‰æ‘˜è¦æ–¹æ³•éƒ½å¤±æ•—æ™‚ï¼Œè¿”å›ä¸€å€‹åŒ…å«åŸå§‹ä¿¡æ¯çš„é€šç”¨è¨Šæ¯
            return (f"âœ… éŒ„éŸ³è½‰æ–‡å­—å·²å®Œæˆã€‚\n"
                    f"â±ï¸ éŒ„éŸ³ç¸½æ™‚é•·ç´„ {estimated_minutes:.0f} åˆ†é˜ (æ–‡æœ¬é•·åº¦ {len(text)} å­—)ã€‚\n"
                    f"ğŸ“ æŠ±æ­‰ï¼Œç”±æ–¼å…§å®¹éé•·æˆ–æŠ€è¡“é™åˆ¶ï¼Œç›®å‰ç„¡æ³•è‡ªå‹•ç”Ÿæˆæ‘˜è¦ã€‚å»ºè­°æ‚¨ç›´æ¥æŸ¥é–±å®Œæ•´çš„é€å­—ç¨¿å…§å®¹ã€‚")
    
    async def _generate_simple_focused_summary(self, text: str) -> str:
        """
        ç°¡åŒ–ç‰ˆçš„é‡é»æ‘˜è¦æ–¹æ³• (ä½œç‚ºä¸­ç­‰é•·åº¦éŒ„éŸ³è™•ç†çš„å‚™ç”¨æ–¹æ¡ˆ)ã€‚
        å°‡æ–‡æœ¬åˆ†å¡Šï¼Œå°å‰é¢å¹¾å¡Šåˆ†åˆ¥ç”Ÿæˆç°¡çŸ­æ‘˜è¦å¾Œåˆä½µã€‚

        Args:
            text (str): éœ€è¦æ‘˜è¦çš„æ–‡æœ¬ã€‚

        Returns:
            str: ç”Ÿæˆçš„ç°¡åŒ–ç‰ˆé‡é»æ‘˜è¦ï¼Œæˆ–åœ¨å¤±æ•—æ™‚å˜—è©¦æ›´çŸ­çš„æ‘˜è¦ã€‚
        """
        try:
            logger.info(f"åŸ·è¡Œã€Œç°¡åŒ–ç‰ˆé‡é»æ‘˜è¦ã€é‡å°é•·åº¦ç‚º {len(text)} çš„æ–‡æœ¬ã€‚")
            chunk_size_simple = 2000 # æ¯å¡Šå¤§å°
            num_chunks_to_process = 3 # æœ€å¤šè™•ç†çš„å¡Šæ•¸
            chunks = [text[i:i+chunk_size_simple] for i in range(0, len(text), chunk_size_simple)]
            
            summaries = []
            # åƒ…è™•ç†å‰é¢å¹¾å¡Šï¼Œæˆ–ç›´åˆ°é”åˆ°è™•ç†ä¸Šé™
            for i, chunk in enumerate(chunks[:num_chunks_to_process]): 
                try:
                    prompt = f"è«‹ç”¨ç¹é«”ä¸­æ–‡ï¼Œç°¡æ½”åœ°ç¸½çµä»¥ä¸‹å…§å®¹ç‰‡æ®µçš„æ ¸å¿ƒè¦é» (ç´„ 50-100 å­—)ï¼š\n\n---\n{chunk}\n---\n\næ ¸å¿ƒè¦é»ï¼š"
                    
                    generation_config_simple = genai_types.GenerationConfig(
                        temperature=0.15,
                        max_output_tokens=1024, # æ¯æ®µæ‘˜è¦é™åˆ¶è¼¸å‡º
                        top_p=0.8,
                        top_k=10
                    )
                    
                    response = await self._call_gemini_with_rotation(prompt, generation_config_simple)
                    # å‡è¨­ _extract_response_text å·²è¢«æ›´æ–°
                    chunk_summary = self._extract_response_text(response, original_text=chunk, summary_type_for_log=f"ç°¡åŒ–ç‰‡æ®µ {i+1}")
                    if chunk_summary:
                        summaries.append(f"ã€ç‰‡æ®µ {i+1} è¦é»ã€‘\n{chunk_summary}")
                    
                    if i < num_chunks_to_process - 1: # ä¸æ˜¯æœ€å¾Œä¸€å¡Šæ™‚æ‰å»¶é²
                         await asyncio.sleep(self.retry_delay / 2 if self.retry_delay > 0.5 else 0.3) # çŸ­æš«å»¶é²

                except Exception as e_chunk:
                    logger.warning(f"è™•ç†ç°¡åŒ–æ‘˜è¦çš„ç¬¬ {i+1} ç‰‡æ®µæ™‚å¤±æ•—: {str(e_chunk)}", exc_info=True)
                    continue # è·³éå¤±æ•—çš„ç‰‡æ®µ
            
            if summaries:
                result = "\n\n---\n\n".join(summaries)
                if len(chunks) > num_chunks_to_process:
                    result += f"\n\nğŸ’¡ **æç¤º**ï¼šä»¥ä¸Šç‚ºåŸºæ–¼æ–‡æœ¬å‰ {num_chunks_to_process * chunk_size_simple} å­—å…ƒï¼ˆç´„ {num_chunks_to_process} å€‹ç‰‡æ®µï¼‰ç”Ÿæˆçš„é‡é»æ‘˜è¦ã€‚å…¨æ–‡å…±ç´„ {len(chunks)} å€‹ç‰‡æ®µã€‚"
                logger.info(f"ã€Œç°¡åŒ–ç‰ˆé‡é»æ‘˜è¦ã€ç”ŸæˆæˆåŠŸï¼Œåˆä½µæ‘˜è¦é•·åº¦: {len(result)}ã€‚")
                return result
            else:
                logger.warning("ã€Œç°¡åŒ–ç‰ˆé‡é»æ‘˜è¦ã€æœªèƒ½å¾ä»»ä½•ç‰‡æ®µä¸­ç”Ÿæˆæœ‰æ•ˆæ‘˜è¦ï¼Œå˜—è©¦æœ€çµ‚å‚™ç”¨æ–¹æ¡ˆ (æ¥µç°¡æ‘˜è¦)ã€‚")
                return await self._generate_short_summary(text[:1500]) # å–æ–‡æœ¬å‰1500å­—é€²è¡Œæœ€ç°¡æ‘˜è¦
                
        except Exception as e:
            logger.error(f"ã€Œç°¡åŒ–ç‰ˆé‡é»æ‘˜è¦ã€éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}ã€‚å˜—è©¦æœ€çµ‚å‚™ç”¨æ–¹æ¡ˆ (æ¥µç°¡æ‘˜è¦)ã€‚", exc_info=True)
            return await self._generate_short_summary(text[:1500]) # å‡ºéŒ¯ä¹Ÿå˜—è©¦æ¥µç°¡æ‘˜è¦

    async def _generate_short_summary(self, text: str) -> str:
        """
        ç”Ÿæˆéå¸¸ç°¡çŸ­çš„æ‘˜è¦ (ä½œç‚ºæœ€çµ‚çš„å‚™ç”¨æ–¹æ¡ˆ)ã€‚
        ä¸»è¦ç”¨æ–¼è™•ç†å‰é¢æ‰€æœ‰æ‘˜è¦æ–¹æ³•éƒ½å¤±æ•—çš„æƒ…æ³ï¼Œæˆ–æ–‡æœ¬æ¥µçŸ­ã€‚

        Args:
            text (str): éœ€è¦æ‘˜è¦çš„æ–‡æœ¬ (é€šå¸¸æ˜¯åŸå§‹æ–‡æœ¬çš„å‰ä¸€éƒ¨åˆ†ï¼Œä¾‹å¦‚å‰1000-1500å­—)ã€‚

        Returns:
            str: ç”Ÿæˆçš„æ¥µç°¡æ‘˜è¦ï¼Œæˆ–ä¸€æ¢æç¤ºè¨Šæ¯ã€‚
        """
        try:
            logger.info(f"åŸ·è¡Œã€Œæ¥µç°¡æ‘˜è¦ã€é‡å°é•·åº¦ç‚º {len(text)} çš„æ–‡æœ¬ã€‚")
            prompt = f"è«‹ç”¨ç¹é«”ä¸­æ–‡ï¼Œä»¥æœ€ç²¾ç°¡çš„æ–¹å¼ç¸½çµä»¥ä¸‹å…§å®¹çš„æ ¸å¿ƒä¸»é¡Œï¼ˆåš´æ ¼é™åˆ¶åœ¨ 100 å­—å…ƒä»¥å…§ï¼‰ï¼š\n\n---\n{text[:1500]}\n---\n\næ ¸å¿ƒä¸»é¡Œï¼š" # é™åˆ¶è¼¸å…¥æ–‡æœ¬é•·åº¦
            
            generation_config_short = genai_types.GenerationConfig(
                temperature=0.1,
                max_output_tokens=512, # é™åˆ¶è¼¸å‡ºé•·åº¦
                top_p=0.7,
                top_k=5
            )

            response = await self._call_gemini_with_rotation(prompt, generation_config_short)
            short_summary_text = self._extract_response_text(response, original_text=text[:1500], summary_type_for_log="æ¥µç°¡æ‘˜è¦")
            
            if short_summary_text:
                 logger.info(f"ã€Œæ¥µç°¡æ‘˜è¦ã€ç”ŸæˆæˆåŠŸ: {short_summary_text}")
                 return f"## ğŸ“ æ¥µç°¡æ‘˜è¦\n\n{short_summary_text}\n\n**æç¤º**ï¼šç”±æ–¼å…ˆå‰è™•ç†é™åˆ¶æˆ–éŒ¯èª¤ï¼Œæ­¤ç‚ºåŸºæ–¼éƒ¨åˆ†å…§å®¹ç”Ÿæˆçš„æ¥µç°¡æ‘˜è¦ã€‚"
            else: # å¦‚æœé€£æ¥µç°¡æ‘˜è¦éƒ½å¤±æ•—
                logger.warning("ã€Œæ¥µç°¡æ‘˜è¦ã€ä¹Ÿæœªèƒ½ç”Ÿæˆæœ‰æ•ˆæ–‡æœ¬ã€‚")
                return ("âœ… éŒ„éŸ³è½‰æ–‡å­—å·²å®Œæˆã€‚\n"
                        "ğŸ“ æŠ±æ­‰ï¼ŒAI æ‘˜è¦åŠŸèƒ½ç›®å‰ç„¡æ³•ç‚ºæ­¤å…§å®¹ç”Ÿæˆæ‘˜è¦ï¼Œå»ºè­°æ‚¨ç›´æ¥æŸ¥é–±å®Œæ•´çš„é€å­—ç¨¿ã€‚")
                
        except Exception as e:
            logger.error(f"ã€Œæ¥µç°¡æ‘˜è¦ã€ç”Ÿæˆä¹Ÿå¤±æ•—: {str(e)}", exc_info=True)
            return ("âœ… éŒ„éŸ³è½‰æ–‡å­—å·²å®Œæˆã€‚\n"
                    "ğŸ“ æŠ±æ­‰ï¼ŒAI æ‘˜è¦åŠŸèƒ½å› æŠ€è¡“å•é¡Œæš«æ™‚ç„¡æ³•ä½¿ç”¨ï¼Œè«‹æŸ¥çœ‹å®Œæ•´çš„é€å­—ç¨¿ã€‚")
    
    def _build_summary_prompt(self, transcript: str, summary_type: str = "é€šç”¨") -> str:
        """
        æ ¹æ“šæä¾›çš„æ–‡å­—ç¨¿å’Œæ‘˜è¦é¡å‹ï¼Œæ§‹å»ºä¸€å€‹çµæ§‹åŒ–çš„æ‘˜è¦æç¤ºè© (Prompt)ã€‚

        Args:
            transcript (str): éŒ„éŸ³è½‰éŒ„çš„å®Œæ•´æ–‡å­—å…§å®¹ã€‚
            summary_type (str, optional): æœŸæœ›çš„æ‘˜è¦é¡å‹ (ä¾‹å¦‚ "å®Œæ•´æ‘˜è¦", "é‡é»æ‘˜è¦")ï¼Œ
                                          ç”¨æ–¼å¾®èª¿æç¤ºè©å…§å®¹ã€‚é è¨­ç‚º "é€šç”¨"ã€‚

        Returns:
            str: æ§‹å»ºå®Œæˆçš„ã€æº–å‚™ç™¼é€çµ¦ Gemini API çš„æç¤ºè©å­—ä¸²ã€‚
        """
        logger.debug(f"é–‹å§‹ç‚ºã€Œ{summary_type}ã€æ§‹å»ºæ‘˜è¦æç¤ºè©ï¼Œæ–‡å­—ç¨¿é•·åº¦: {len(transcript)}ã€‚")
        # åŸºç¤æç¤ºè©çµæ§‹ï¼Œå¼·èª¿çµæ§‹åŒ–å’Œè©³ç›¡æ€§
        # é‡å° Gemini Pro 1.5 Flash çš„ç‰¹æ€§é€²è¡Œå„ªåŒ–ï¼Œå®ƒèƒ½è™•ç†è¼ƒé•·çš„ä¸Šä¸‹æ–‡
        # æç¤ºè©ä¸­æ˜ç¢ºè¦æ±‚ä½¿ç”¨ç¹é«”ä¸­æ–‡
        return f"""
**ä»»å‹™ï¼š** è«‹ç‚ºä»¥ä¸‹ã€{summary_type}ã€‘çš„éŒ„éŸ³è½‰éŒ„å…§å®¹ç”Ÿæˆä¸€ä»½è©³ç´°ã€çµæ§‹åŒ–ä¸”ç²¾ç¢ºçš„æ‘˜è¦å ±å‘Šã€‚

**åŸå§‹è½‰éŒ„å…§å®¹ï¼š**
---
{transcript}
---

**æ‘˜è¦å ±å‘Šæ ¼å¼è¦æ±‚ï¼š**

è«‹åš´æ ¼éµå¾ªä»¥ä¸‹ Markdown æ ¼å¼è¼¸å‡ºæ‚¨çš„æ‘˜è¦å ±å‘Šï¼Œä¸¦ç¢ºä¿æ¯å€‹éƒ¨åˆ†éƒ½å¾—åˆ°å……åˆ†é—¡è¿°ã€‚ä½¿ç”¨ã€ç¹é«”ä¸­æ–‡ã€‘é€²è¡Œå›æ‡‰ã€‚

## ğŸ“ æœƒè­°/å°è©±æ‘˜è¦å ±å‘Š

### ğŸ¯ æ ¸å¿ƒè­°é¡Œèˆ‡ä¸»è¦ç›®çš„ (Core Issues & Main Objectives)
*   **è­°é¡Œ/ç›®çš„ 1ï¼š** [å°ç¬¬ä¸€å€‹æ ¸å¿ƒè­°é¡Œæˆ–æœƒè­°ç›®çš„é€²è¡Œè‡³å°‘2-3å¥çš„è©³ç´°æè¿°ï¼Œè§£é‡‹å…¶èƒŒæ™¯å’Œé‡è¦æ€§ã€‚]
*   **è­°é¡Œ/ç›®çš„ 2ï¼š** [å°ç¬¬äºŒå€‹æ ¸å¿ƒè­°é¡Œæˆ–æœƒè­°ç›®çš„é€²è¡Œè‡³å°‘2-3å¥çš„è©³ç´°æè¿°ï¼Œè§£é‡‹å…¶èƒŒæ™¯å’Œé‡è¦æ€§ã€‚]
*   **(ä¾æ­¤é¡æ¨ï¼Œåˆ—å‡º3-5å€‹)**

### ğŸ“‹ è©³ç´°å…§å®¹èˆ‡é—œéµè¨è«–é» (Detailed Content & Key Discussion Points)
*   **è¨è«–é» 1 - [ä¸»é¡Œ]ï¼š** [é‡å°æ­¤ä¸»é¡Œï¼Œè©³ç´°èªªæ˜è¨è«–ä¸­çš„é‡è¦è§€é»ã€æå‡ºçš„è«–æ“šã€ç›¸é—œæ•¸æ“šæˆ–æ¡ˆä¾‹åˆ†æã€‚å…§å®¹æ‡‰å…·é«”ä¸”æœ‰æ·±åº¦ã€‚]
*   **è¨è«–é» 2 - [ä¸»é¡Œ]ï¼š** [åŒä¸Šï¼Œç¢ºä¿æ¯å€‹è¨è«–é»éƒ½æœ‰å……åˆ†çš„é—¡è¿°ï¼Œè‡³å°‘æ¶µè“‹5-8å€‹æ•´é«”é—œéµé»ã€‚]
*   **(ä¾æ­¤é¡æ¨)**

### âœ… é‡è¦æ±ºç­–èˆ‡è¡Œå‹•é …ç›® (Key Decisions & Action Items)
*   **æ±ºç­–/è¡Œå‹• 1ï¼š** [æ˜ç¢ºåˆ—å‡ºå·²é”æˆçš„æ±ºç­–æˆ–éœ€è¦æ¡å–çš„å…·é«”è¡Œå‹•ã€‚]
    *   **è² è²¬äººï¼š** [æŒ‡å®šè² è²¬äººï¼Œå¦‚é©ç”¨]
    *   **æˆªæ­¢æ—¥æœŸ/ç‹€æ…‹ï¼š** [é è¨ˆå®Œæˆæ—¥æœŸæˆ–ç›®å‰ç‹€æ…‹ï¼Œå¦‚ 'é€²è¡Œä¸­', 'å·²å®Œæˆ']
    *   **ç›¸é—œç´°ç¯€ï¼š** [è£œå……å¿…è¦çš„åŸ·è¡Œç´°ç¯€æˆ–ä¸Šä¸‹æ–‡]
*   **(ä¾æ­¤é¡æ¨ï¼Œåˆ—å‡ºæ‰€æœ‰é‡è¦æ±ºç­–å’Œè¡Œå‹•é …ç›®)**

### ğŸ’¡ ç¶œåˆè¦‹è§£èˆ‡æ·±å±¤çµè«– (Overall Insights & In-depth Conclusions)
*   **è¦‹è§£/çµè«– 1ï¼š** [åŸºæ–¼æ•´é«”è¨è«–ï¼Œç¸½çµä¸€å€‹é‡è¦çš„è¦‹è§£æˆ–æ·±å±¤çµè«–ã€‚]
    *   **æ¨æ–·ä¾æ“š/æ½›åœ¨å½±éŸ¿ï¼š** [ç°¡è¿°æ­¤è¦‹è§£/çµè«–çš„æ¨æ–·éç¨‹ã€ä¾æ“šçš„è³‡è¨Šï¼Œæˆ–å®ƒå¯èƒ½å¸¶ä¾†çš„æ½›åœ¨å½±éŸ¿ã€‚]
*   **(ä¾æ­¤é¡æ¨ï¼Œè‡³å°‘3-5å€‹)**

### ğŸ”‘ å…¨æ–‡æ ¸å¿ƒé—œéµå­— (Core Keywords)
[è«‹å¾å…¨æ–‡ä¸­æå–è‡³å°‘10-15å€‹èƒ½å¤ é«˜åº¦æ¦‚æ‹¬æ ¸å¿ƒå…§å®¹çš„é—œéµå­—æˆ–é—œéµçŸ­èªï¼Œä½¿ç”¨é€—è™Ÿåˆ†éš”ã€‚ä¾‹å¦‚ï¼šå¸‚å ´åˆ†æ, ç”¢å“ç­–ç•¥, é ç®—è¦åŠƒ, å®¢æˆ¶å›é¥‹, ç«¶çˆ­å°æ‰‹å‹•æ…‹, ...]

**é‡è¦æŒ‡ç¤ºï¼š**
- **èªè¨€ï¼š** è«‹å‹™å¿…ä½¿ç”¨ã€ç¹é«”ä¸­æ–‡ã€‘ã€‚
- **è©³ç›¡æ€§ï¼š** æ‘˜è¦çš„è©³ç´°ç¨‹åº¦æ‡‰èˆ‡åŸæ–‡é•·åº¦æˆæ­£æ¯”ã€‚å°æ–¼è¼ƒé•·çš„æ–‡æœ¬ï¼Œæ‘˜è¦æ‡‰åŒ…å«æ›´è±å¯Œçš„ç´°ç¯€å’Œæ›´æ·±å…¥çš„åˆ†æã€‚
- **æº–ç¢ºæ€§ï¼š** ç¢ºä¿æ‘˜è¦å…§å®¹æº–ç¢ºåæ˜ åŸæ–‡çš„æ„æ¶µï¼Œé¿å…ä¸»è§€è‡†æ–·æˆ–è³‡è¨Šéºæ¼ã€‚
- **çµæ§‹åŒ–ï¼š** åš´æ ¼éµå¾ªä¸Šè¿° Markdown æ ¼å¼ï¼Œç¢ºä¿å ±å‘Šçš„æ˜“è®€æ€§å’Œå°ˆæ¥­æ€§ã€‚
- **é¿å…éç°¡ï¼š** å°æ–¼ä¿¡æ¯é‡å¤§çš„æ–‡æœ¬ï¼Œæ‘˜è¦æ‡‰æœ‰è¶³å¤ çš„å­—æ•¸ä¾†æ¶µè“‹é—œéµä¿¡æ¯ã€‚ä¾‹å¦‚ï¼Œå°æ–¼è¶…éä¸€è¬å­—çš„æ–‡æœ¬ï¼Œæ‘˜è¦å­—æ•¸æœŸæœ›åœ¨1000å­—ä»¥ä¸Šã€‚
"""
    
    async def _call_gemini_with_rotation(self, prompt: str, generation_config: genai_types.GenerationConfig) -> Optional[genai_types.GenerateContentResponse]:
        """
        ç•°æ­¥èª¿ç”¨ Google Gemini API ç”Ÿæˆå…§å®¹ï¼Œä¸¦å¯¦ç¾ API é‡‘é‘°è¼ªæ›å’Œé‡è©¦æ©Ÿåˆ¶ã€‚

        æ­¤æ–¹æ³•æœƒä¾åºå˜—è©¦ä½¿ç”¨ `self.api_keys` åˆ—è¡¨ä¸­çš„ API é‡‘é‘°ã€‚
        å¦‚æœä¸€æ¬¡èª¿ç”¨å¤±æ•— (ä¾‹å¦‚å› é…é¡é™åˆ¶ã€æš«æ™‚æ€§éŒ¯èª¤ç­‰)ï¼Œå®ƒæœƒè‡ªå‹•åˆ‡æ›åˆ°ä¸‹ä¸€å€‹é‡‘é‘°ä¸¦é‡è©¦ã€‚
        é‡è©¦ä¹‹é–“æœƒæœ‰æŒ‡æ•¸é€€é¿å»¶é²ã€‚

        Args:
            prompt (str): è¦ç™¼é€çµ¦ Gemini API çš„æç¤ºè©ã€‚
            generation_config (genai_types.GenerationConfig): Gemini API çš„ç”Ÿæˆé…ç½®ã€‚

        Returns:
            Optional[genai_types.GenerateContentResponse]: Gemini API çš„æˆåŠŸå›æ‡‰ï¼Œå¦‚æœæ‰€æœ‰é‡è©¦å‡å¤±æ•—å‰‡è¿”å› None æˆ–æ‹‹å‡ºæœ€å¾Œä¸€å€‹éŒ¯èª¤ã€‚

        Raises:
            Exception: å¦‚æœæ‰€æœ‰ API é‡‘é‘°å’Œé‡è©¦å˜—è©¦å‡å¤±æ•—ï¼Œå‰‡æ‹‹å‡ºæœ€å¾Œä¸€æ¬¡é‡åˆ°çš„ä¾‹å¤–ã€‚
        """
        last_error: Optional[Exception] = None # ç”¨æ–¼è¨˜éŒ„æœ€å¾Œä¸€æ¬¡ç™¼ç”Ÿçš„éŒ¯èª¤
        
        # å¤–å±¤å¾ªç’°ï¼šéæ­·æ‰€æœ‰ API é‡‘é‘°
        for i in range(len(self.api_keys)): 
            current_key_index = (self.current_api_key_index + i) % len(self.api_keys)
            current_api_key = self.api_keys[current_key_index]
            logger.info(f"å˜—è©¦ä½¿ç”¨ API é‡‘é‘°ç´¢å¼• {current_key_index} (é‡‘é‘°å°¾è™Ÿ: ...{current_api_key[-4:] if len(current_api_key) > 4 else '****'}) é€²è¡Œ Gemini API èª¿ç”¨ã€‚")
            
            # è¨­å®šç•¶å‰ genai SDK ä½¿ç”¨çš„ API é‡‘é‘°
            genai.configure(api_key=current_api_key)

            try:
                # å…§å±¤å¾ªç’°ï¼šé‡å°ç•¶å‰ API é‡‘é‘°é€²è¡Œé‡è©¦
                for attempt in range(self.max_retries + 1): # +1 æ˜¯å› ç‚ºç¬¬ä¸€æ¬¡å˜—è©¦ï¼ˆattempt=0ï¼‰ä¸ç®—é‡è©¦
                    try:
                        # å‰µå»ºæ¨¡å‹å¯¦ä¾‹
                        model = genai.GenerativeModel(self.model_name)
                        
                        # ä½¿ç”¨ asyncio.to_thread åŸ·è¡ŒåŒæ­¥çš„ SDK èª¿ç”¨ï¼Œä½¿å…¶åœ¨ç•°æ­¥ä¸Šä¸‹æ–‡ä¸­ä¸é˜»å¡äº‹ä»¶å¾ªç’°
                        response = await asyncio.to_thread( 
                            model.generate_content,
                            contents=prompt,
                            generation_config=generation_config,
                            # request_options={"timeout": 60} # å¯é¸ï¼šè¨­å®šè«‹æ±‚è¶…æ™‚ (ç§’)
                        )
                        
                        logger.info(f"Gemini API èª¿ç”¨æˆåŠŸ (ä½¿ç”¨é‡‘é‘°ç´¢å¼• {current_key_index}ï¼Œç¬¬ {attempt + 1} æ¬¡å˜—è©¦)ã€‚")
                        self.current_api_key_index = current_key_index # æ›´æ–°ç•¶å‰æˆåŠŸçš„é‡‘é‘°ç´¢å¼•ï¼Œä¸‹æ¬¡å„ªå…ˆä½¿ç”¨æ­¤é‡‘é‘°
                        return response # æˆåŠŸå‰‡è¿”å›å›æ‡‰
                    
                    except Exception as e_attempt: # æ•ç²ç•¶å‰å˜—è©¦çš„éŒ¯èª¤
                        last_error = e_attempt
                        logger.warning(f"âš ï¸ Gemini API èª¿ç”¨å˜—è©¦ {attempt + 1} å¤±æ•— (ä½¿ç”¨é‡‘é‘°ç´¢å¼• {current_key_index}): {type(e_attempt).__name__} - {str(e_attempt)}")
                        
                        # å¦‚æœæ˜¯ç‰¹å®šçš„ã€å¯é‡è©¦çš„éŒ¯èª¤é¡å‹ (ä¾‹å¦‚è³‡æºè€—ç›¡ã€æš«æ™‚æ€§ä¼ºæœå™¨éŒ¯èª¤)ï¼Œå‰‡é€²è¡Œé‡è©¦
                        # TODO: æ›´ç²¾ç´°åœ°å€åˆ†éŒ¯èª¤é¡å‹ä»¥æ±ºå®šæ˜¯å¦é‡è©¦
                        # ä¾‹å¦‚: if isinstance(e_attempt, (types.ResourceExhausted, types.ServiceUnavailable)):
                        if attempt < self.max_retries:
                            delay = self.retry_delay * (2 ** attempt) # æŒ‡æ•¸é€€é¿ç­–ç•¥
                            logger.info(f"å°‡åœ¨ {delay:.2f} ç§’å¾Œä½¿ç”¨ç›¸åŒé‡‘é‘°é‡è©¦...")
                            await asyncio.sleep(delay)
                        else: # ç•¶å‰é‡‘é‘°çš„æ‰€æœ‰é‡è©¦å·²ç”¨ç›¡
                            logger.error(f"API é‡‘é‘°ç´¢å¼• {current_key_index} çš„æ‰€æœ‰é‡è©¦å˜—è©¦å‡å¤±æ•—ã€‚")
                            break # è·³å‡ºå…§å±¤é‡è©¦å¾ªç’°ï¼Œæº–å‚™å˜—è©¦ä¸‹ä¸€å€‹ API é‡‘é‘°
                
                # å¦‚æœå…§å±¤å¾ªç’°æ˜¯å› ç‚º break è·³å‡ºçš„ (å³ç•¶å‰é‡‘é‘°çš„æ‰€æœ‰é‡è©¦å‡å¤±æ•—)ï¼Œå‰‡ç¹¼çºŒå¤–å±¤å¾ªç’°å˜—è©¦ä¸‹ä¸€å€‹é‡‘é‘°
                # æª¢æŸ¥ last_error æ˜¯å¦æ˜¯ç”±æ–¼æœ€å¾Œä¸€æ¬¡å˜—è©¦å¤±æ•—è€Œè¨­å®šçš„
                if last_error and attempt == self.max_retries: 
                    # åªæœ‰åœ¨ç¢ºå¯¦æ˜¯å› ç‚ºé‡è©¦æ¬¡æ•¸è€—ç›¡æ‰ç¹¼çºŒå˜—è©¦ä¸‹ä¸€å€‹é‡‘é‘°
                    if i < len(self.api_keys) - 1: # å¦‚æœé‚„æœ‰å…¶ä»–é‡‘é‘°
                        logger.info(f"æº–å‚™å˜—è©¦ä¸‹ä¸€å€‹ API é‡‘é‘°...")
                        await asyncio.sleep(self.retry_delay) # åˆ‡æ›é‡‘é‘°å‰ç¨ä½œå»¶é²
                    continue # å˜—è©¦ä¸‹ä¸€å€‹ API é‡‘é‘°
                # å¦‚æœä¸æ˜¯å› ç‚ºé‡è©¦è€—ç›¡ (ä¾‹å¦‚ï¼Œæ˜¯ä¸€å€‹ä¸å¯é‡è©¦çš„éŒ¯èª¤ç›´æ¥è·³å‡º)ï¼Œå‰‡ä¸æ‡‰ç¹¼çºŒ
                # ä½†ç›®å‰çš„é‚è¼¯æ˜¯ï¼Œåªè¦å…§å±¤å¾ªç’°çµæŸï¼ˆç„¡è«–æ˜¯ break é‚„æ˜¯æ­£å¸¸å®Œæˆï¼‰ï¼Œå¦‚æœæ²’æœ‰ return responseï¼Œå°±æœƒåˆ°é€™è£¡
                # éœ€è¦ç¢ºä¿åªæœ‰åœ¨æ˜ç¢ºçŸ¥é“å¯ä»¥å˜—è©¦ä¸‹ä¸€å€‹é‡‘é‘°æ™‚æ‰ continue
                
            except Exception as e_key_config: # æ•ç²èˆ‡é‡‘é‘°é…ç½®æˆ–å®¢æˆ¶ç«¯åˆå§‹åŒ–ç›¸é—œçš„æ›´åš´é‡éŒ¯èª¤
                last_error = e_key_config
                logger.error(f"é…ç½®æˆ–ä½¿ç”¨ API é‡‘é‘°ç´¢å¼• {current_key_index} æ™‚ç™¼ç”Ÿåš´é‡éŒ¯èª¤: {type(e_key_config).__name__} - {str(e_key_config)}", exc_info=True)
                # å¦‚æœæ˜¯é‡‘é‘°ç„¡æ•ˆç­‰éŒ¯èª¤ï¼Œç›´æ¥å˜—è©¦ä¸‹ä¸€å€‹é‡‘é‘°
                # TODO: æ ¹æ“šå¯¦éš›çš„ Google API éŒ¯èª¤é¡å‹ä¾†åˆ¤æ–·æ˜¯å¦ç‚ºé‡‘é‘°ç„¡æ•ˆéŒ¯èª¤
                if "API_KEY_INVALID" in str(e_key_config).upper() or \
                   "API_KEY_NOT_AUTHORIZED" in str(e_key_config).upper() or \
                   "PERMISSION_DENIED" in str(e_key_config).upper():
                    logger.warning(f"API é‡‘é‘°ç´¢å¼• {current_key_index} å¯èƒ½ç„¡æ•ˆæˆ–æ¬Šé™ä¸è¶³ï¼Œå˜—è©¦ä¸‹ä¸€å€‹é‡‘é‘°ã€‚")
                    if i < len(self.api_keys) - 1: # å¦‚æœé‚„æœ‰å…¶ä»–é‡‘é‘°
                         await asyncio.sleep(self.retry_delay) 
                    continue # å˜—è©¦ä¸‹ä¸€å€‹ API é‡‘é‘°
                else: # å¦‚æœæ˜¯å…¶ä»–é¡å‹çš„åš´é‡éŒ¯èª¤ï¼Œå¯èƒ½ç„¡éœ€å†è©¦å…¶ä»–é‡‘é‘°ï¼Œç›´æ¥è·³å‡ºå¤–å±¤å¾ªç’°
                    break 
        
        # å¦‚æœéæ­·æ‰€æœ‰ API é‡‘é‘°å’Œæ‰€æœ‰é‡è©¦å˜—è©¦å¾Œä»ç„¶å¤±æ•—
        logger.critical(f"æ‰€æœ‰ API é‡‘é‘° ({len(self.api_keys)} å€‹) å’Œé‡è©¦å˜—è©¦ ({self.max_retries} æ¬¡/æ¯å€‹é‡‘é‘°) å‡å‘Šå¤±æ•—ã€‚")
        if last_error:
            raise last_error # æ‹‹å‡ºæœ€å¾Œä¸€æ¬¡é‡åˆ°çš„éŒ¯èª¤
        else:
            # é€™ç¨®æƒ…æ³ç†è«–ä¸Šä¸æ‡‰ç™¼ç”Ÿï¼Œå› ç‚ºè‡³å°‘æœƒæœ‰ä¸€å€‹ last_error è¢«è¨˜éŒ„
            raise Exception("Gemini API èª¿ç”¨å¾¹åº•å¤±æ•—ï¼Œä¸”æœªè¨˜éŒ„ç‰¹å®šçš„æœ€çµ‚éŒ¯èª¤ã€‚")

    def _extract_response_text(self, response: Optional[genai_types.GenerateContentResponse], original_text: str, 
                               is_structured_summary: bool = False, summary_type_for_log: str = "é€šç”¨") -> str:
        """
        å¾ Gemini API çš„å›æ‡‰ä¸­æå–æ–‡æœ¬å…§å®¹ï¼Œä¸¦è™•ç†å„ç¨®å¯èƒ½çš„å®Œæˆç‹€æ…‹ã€‚

        Args:
            response (Optional[genai_types.GenerateContentResponse]): å¾ Gemini API æ”¶åˆ°çš„å›æ‡‰ç‰©ä»¶ã€‚
            original_text (str): åŸå§‹è¼¸å…¥æ–‡æœ¬ï¼Œä¸»è¦ç”¨æ–¼æ—¥èªŒè¨˜éŒ„é•·åº¦ç­‰å…ƒä¿¡æ¯ï¼Œä¸ç›´æ¥åƒèˆ‡æå–ã€‚
            is_structured_summary (bool, optional): æŒ‡ç¤ºæ˜¯å¦æœŸæœ›çµæ§‹åŒ–æ‘˜è¦ã€‚
                                                  å¦‚æœç‚º True ä¸”å› é•·åº¦é™åˆ¶å°è‡´æ‘˜è¦ä¸å®Œæ•´ï¼Œæœƒå˜—è©¦è¿”å›éƒ¨åˆ†çµæœã€‚
                                                  é è¨­ç‚º Falseã€‚
            summary_type_for_log (str, optional): ç”¨æ–¼æ—¥èªŒè¨˜éŒ„çš„æ‘˜è¦é¡å‹ã€‚é è¨­ç‚º "é€šç”¨"ã€‚

        Returns:
            str: æå–åˆ°çš„æ–‡æœ¬æ‘˜è¦ã€‚

        Raises:
            Exception: å¦‚æœç„¡æ³•å¾å›æ‡‰ä¸­æå–æœ‰æ•ˆçš„æ–‡æœ¬æ‘˜è¦ (ä¾‹å¦‚ API å›æ‡‰æ ¼å¼éŒ¯èª¤ã€å®‰å…¨é˜»æ“‹ç­‰)ã€‚
        """
        if not response or not hasattr(response, 'candidates') or not response.candidates:
            logger.warning(f"Gemini API å›æ‡‰ç„¡æ•ˆæˆ–ç„¡å€™é¸å…§å®¹ ({summary_type_for_log})ã€‚")
            raise Exception(f"ç„¡æ³•ç”Ÿæˆã€Œ{summary_type_for_log}ã€ï¼šAPI å›æ‡‰ä¸­ç„¡å€™é¸å…§å®¹æˆ–å›æ‡‰æ ¼å¼ä¸æ­£ç¢ºã€‚")
        
        candidate = response.candidates[0] # é€šå¸¸å–ç¬¬ä¸€å€‹å€™é¸çµæœ
        
        # è™•ç† finish_reason
        finish_reason_enum = candidate.finish_reason
        finish_reason_str = genai_types.FinishReason(finish_reason_enum).name if finish_reason_enum else "UNKNOWN"
        
        logger.info(f"Gemini API å›æ‡‰çš„å®ŒæˆåŸå›  ({summary_type_for_log})ï¼šã€Œ{finish_reason_str}ã€ã€‚")
        
        # æª¢æŸ¥æ˜¯å¦æœ‰å®‰å…¨è©•ç´šå°è‡´å…§å®¹è¢«é˜»æ“‹
        if candidate.safety_ratings:
            for rating in candidate.safety_ratings:
                # å‡è¨­åš´é‡ç­‰ç´šé«˜æ–¼ HARM_PROBABILITY_NEGLIGIBLE éƒ½è¦–ç‚ºæ½›åœ¨å•é¡Œ
                # HARM_PROBABILITY_LOW, HARM_PROBABILITY_MEDIUM, HARM_PROBABILITY_HIGH
                if rating.probability > genai_types.HarmProbability.NEGLIGIBLE: # å¯¦éš›æšèˆ‰å€¼å¯èƒ½ä¸åŒï¼Œéœ€æŸ¥é–±SDK
                    logger.warning(f"Gemini API å›æ‡‰åŒ…å«æ½›åœ¨ä¸å®‰å…¨å…§å®¹ ({summary_type_for_log})ï¼šé¡åˆ¥ {rating.category.name}, æ©Ÿç‡ {rating.probability.name}ã€‚")
                    # å¦‚æœ finish_reason ä¸æ˜¯ SAFETYï¼Œä½† safety_rating æŒ‡å‡ºå•é¡Œï¼Œä¹Ÿæ‡‰è¬¹æ…è™•ç†
                    if finish_reason_enum != genai_types.FinishReason.SAFETY:
                         # å³ä½¿ä¸æ˜¯å› å®‰å…¨åœæ­¢ï¼Œä½†æª¢æ¸¬åˆ°é¢¨éšªï¼Œä¹Ÿè¿”å›å®‰å…¨æç¤º
                         return f"âš ï¸ AIåµæ¸¬åˆ°å›æ‡‰ä¸­å¯èƒ½åŒ…å«ä¸é©å®œå…§å®¹ (é¡åˆ¥: {rating.category.name})ï¼Œå› æ­¤ç„¡æ³•å®Œæ•´æä¾›æ‘˜è¦ã€‚"
        
        # æ ¹æ“š finish_reason æ±ºå®šå¦‚ä½•è™•ç†
        if finish_reason_enum == genai_types.FinishReason.STOP: # æ­£å¸¸å®Œæˆ
            if hasattr(response, 'text') and response.text and response.text.strip():
                result = response.text.strip()
                logger.info(f"ã€Œ{summary_type_for_log}ã€æˆåŠŸç”Ÿæˆï¼Œæ‘˜è¦é•·åº¦: {len(result)} å­—å…ƒã€‚")
                return result
            else:
                logger.warning(f"Gemini API æ­£å¸¸åœæ­¢ï¼Œä½†æœªè¿”å›æœ‰æ•ˆæ–‡æœ¬å…§å®¹ ({summary_type_for_log})ã€‚")
                raise Exception(f"ã€Œ{summary_type_for_log}ã€ç”Ÿæˆç•°å¸¸ï¼šAI æ­£å¸¸åœæ­¢ä½†æœªæä¾›æ–‡æœ¬ã€‚")
        elif finish_reason_enum == genai_types.FinishReason.SAFETY: # å› å®‰å…¨è¨­å®šåœæ­¢
            logger.warning(f"Gemini API å› å®‰å…¨æ€§åŸå› åœæ­¢ç”Ÿæˆ ({summary_type_for_log})ã€‚åŸå§‹æ–‡æœ¬é•·åº¦: {len(original_text)}ã€‚")
            return "âš ï¸ æŠ±æ­‰ï¼Œç”±æ–¼å…§å®¹å¯èƒ½æ¶‰åŠæ•æ„Ÿè³‡è¨Šæˆ–é•åä½¿ç”¨æ”¿ç­–ï¼ŒAI ç„¡æ³•å®Œæˆæœ¬æ¬¡æ‘˜è¦ã€‚è«‹æª¢æŸ¥æ‚¨çš„æ–‡æœ¬å…§å®¹ä¸¦é‡è©¦ã€‚"
        elif finish_reason_enum == genai_types.FinishReason.MAX_TOKENS: # é”åˆ°æœ€å¤§ Token é™åˆ¶
            logger.warning(f"Gemini API å› é”åˆ°æœ€å¤§ Token é™åˆ¶è€Œåœæ­¢ ({summary_type_for_log})ã€‚")
            if hasattr(response, 'text') and response.text and response.text.strip(): # å³ä½¿é”åˆ°é™åˆ¶ï¼Œæœ‰æ™‚ä¹Ÿæœƒè¿”å›éƒ¨åˆ†å…§å®¹
                logger.info(f"è¿”å›ã€Œ{summary_type_for_log}ã€çš„éƒ¨åˆ†çµæœï¼Œå› é”åˆ°æœ€å¤§ Token é™åˆ¶ã€‚")
                return f"{response.text.strip()}\n\nâš ï¸ **æ³¨æ„ï¼šæ‘˜è¦å¯èƒ½å› å·²é”å…§å®¹é•·åº¦ä¸Šé™è€Œæœªå®Œæ•´ç”Ÿæˆã€‚**"
            else: # å¦‚æœæ²’æœ‰éƒ¨åˆ†å…§å®¹ï¼Œå‰‡èªç‚ºæ˜¯å€‹å•é¡Œ
                raise Exception(f"ã€Œ{summary_type_for_log}ã€ç”Ÿæˆå¤±æ•—ï¼šå·²é”å…§å®¹é•·åº¦ä¸Šé™ä¸”ç„¡éƒ¨åˆ†çµæœè¿”å›ã€‚")
        elif finish_reason_enum == genai_types.FinishReason.RECITATION: # å…§å®¹éå¤šå¼•ç”¨ä¾†æºææ–™
             logger.warning(f"Gemini API å› åµæ¸¬åˆ°éå¤šå¼•ç”¨è€Œåœæ­¢ç”Ÿæˆ ({summary_type_for_log})ã€‚")
             return "âš ï¸ AI åµæ¸¬åˆ°ç”Ÿæˆå…§å®¹å¯èƒ½éå¤šç›´æ¥å¼•ç”¨ä¾†æºè³‡æ–™ï¼Œç‚ºé¿å…ç‰ˆæ¬Šç–‘æ…®ï¼Œå·²åœæ­¢æœ¬æ¬¡æ‘˜è¦ã€‚å»ºè­°èª¿æ•´æç¤ºæˆ–æ–‡æœ¬å…§å®¹ã€‚"
        else: # å…¶ä»–æœªçŸ¥æˆ–æœªæ˜ç¢ºè™•ç†çš„å®ŒæˆåŸå›  (ä¾‹å¦‚ LENGTH, UNKNOWN, UNSPECIFIED)
            logger.warning(f"Gemini API è¿”å›æœªæ˜ç¢ºè™•ç†çš„å®ŒæˆåŸå›  ({summary_type_for_log})ï¼šã€Œ{finish_reason_str}ã€ã€‚")
            if hasattr(response, 'text') and response.text and response.text.strip(): # å˜—è©¦è¿”å›ä»»ä½•å¯ç”¨æ–‡æœ¬
                logger.info(f"è¿”å›ã€Œ{summary_type_for_log}ã€çš„éƒ¨åˆ†çµæœï¼Œå®ŒæˆåŸå› ï¼šã€Œ{finish_reason_str}ã€ã€‚")
                return f"{response.text.strip()}\n\nâš ï¸ **æ³¨æ„ï¼šæ‘˜è¦å¯èƒ½å› ã€Œ{finish_reason_str}ã€åŸå› è€Œæœªå®Œæ•´ç”Ÿæˆã€‚**"
            else:
                raise Exception(f"ã€Œ{summary_type_for_log}ã€ç”Ÿæˆç•°å¸¸ï¼Œå®ŒæˆåŸå› ï¼šã€Œ{finish_reason_str}ã€ï¼Œä¸”ç„¡æœ‰æ•ˆæ–‡æœ¬è¿”å›ã€‚")
    
    async def analyze_sentiment(self, text: str) -> Dict[str, Any]:
        """
        (å¯¦é©—æ€§åŠŸèƒ½) ä½¿ç”¨ Gemini åˆ†æè¼¸å…¥æ–‡å­—çš„æƒ…æ„Ÿå‚¾å‘ã€‚

        Args:
            text (str): éœ€è¦åˆ†ææƒ…æ„Ÿçš„æ–‡å­—ã€‚

        Returns:
            Dict[str, Any]: åŒ…å«æƒ…æ„Ÿåˆ†æçµæœçš„å­—å…¸ï¼Œ
                            ä¾‹å¦‚ `{"overall_sentiment": "positive", "confidence": 0.85, ...}`ã€‚
                            å¦‚æœåˆ†æå¤±æ•—ï¼Œå¯èƒ½è¿”å›åŒ…å«éŒ¯èª¤è¨Šæ¯çš„å­—å…¸æˆ–æ‹‹å‡ºä¾‹å¤–ã€‚
        
        Raises:
            Exception: å¦‚æœæƒ…æ„Ÿåˆ†æéç¨‹ä¸­ç™¼ç”Ÿåš´é‡éŒ¯èª¤ã€‚
        """
        logger.info(f"é–‹å§‹å°é•·åº¦ç‚º {len(text)} çš„æ–‡æœ¬é€²è¡Œæƒ…æ„Ÿåˆ†æã€‚")
        try:
            # æç¤ºè©æŒ‡å°æ¨¡å‹è¿”å› JSON æ ¼å¼çš„æƒ…æ„Ÿåˆ†æçµæœ
            prompt = f"""
è«‹ä»”ç´°åˆ†æä»¥ä¸‹æä¾›çš„æ–‡å­—å…§å®¹ï¼Œä¸¦åˆ¤æ–·å…¶æ•´é«”æƒ…æ„Ÿå‚¾å‘ã€‚
æ‚¨çš„åˆ†æçµæœéœ€è¦ä»¥ã€JSONæ ¼å¼ã€‘è¿”å›ï¼ŒåŒ…å«ä»¥ä¸‹éµå€¼ï¼š
- "overall_sentiment": å­—ä¸²ï¼Œè¡¨ç¤ºæ•´é«”æƒ…æ„Ÿï¼ˆä¾‹å¦‚ "positive", "negative", "neutral", "mixed"ï¼‰ã€‚
- "confidence_score": æµ®é»æ•¸ (0.0 è‡³ 1.0)ï¼Œè¡¨ç¤ºæ‚¨å°æ•´é«”æƒ…æ„Ÿåˆ¤æ–·çš„ä¿¡å¿ƒç¨‹åº¦ã€‚
- "detected_emotions": å­—ä¸²åˆ—è¡¨ï¼Œåˆ—å‡ºæ–‡æœ¬ä¸­å¯èƒ½åŒ…å«çš„å…·é«”æƒ…æ„Ÿæ¨™ç±¤ï¼ˆä¾‹å¦‚ ["å–œæ‚…", "æœŸå¾…", "æ“”æ†‚", "ä¸æ»¿"]ï¼Œè‹¥ç„¡æ˜é¡¯ç‰¹å®šæƒ…æ„Ÿå‰‡ç‚ºç©ºåˆ—è¡¨ï¼‰ã€‚
- "key_phrases_contributing_sentiment": å­—ä¸²åˆ—è¡¨ï¼Œåˆ—å‡ºæ–‡æœ¬ä¸­æœ€èƒ½é«”ç¾ä¸Šè¿°æƒ…æ„Ÿå‚¾å‘çš„é—œéµçŸ­èªæˆ–å¥å­ã€‚

æ–‡å­—å…§å®¹å¦‚ä¸‹ï¼š
---
{text[:5000]} 
---

è«‹åš´æ ¼æŒ‰ç…§ä¸Šè¿° JSON çµæ§‹è¼¸å‡ºæ‚¨çš„åˆ†æçµæœã€‚
"""
            # é™åˆ¶è¼¸å…¥æ–‡æœ¬é•·åº¦ä»¥å„ªåŒ–æ•ˆèƒ½å’Œæˆæœ¬
            
            generation_config = genai_types.GenerationConfig(
                temperature=0.1, # ä½æº«ä»¥ç²å¾—æ›´ä¸€è‡´å’Œçµæ§‹åŒ–çš„ JSON è¼¸å‡º
                max_output_tokens=1024, # è¶³å¤  JSON è¼¸å‡º
                top_p=0.8, # ä¿æŒä¸€å®šçš„ç¢ºå®šæ€§
                top_k=10
            )
            
            response = await self._call_gemini_with_rotation(prompt, generation_config)
            result_text = self._extract_response_text(response, original_text=text[:5000], summary_type_for_log="æƒ…æ„Ÿåˆ†æ")
            
            # å˜—è©¦å°‡æ¨¡å‹å›æ‡‰è§£æç‚º JSON ç‰©ä»¶
            try:
                sentiment_data = json.loads(result_text)
                # åŸºæœ¬çš„çµæ§‹é©—è­‰
                if not all(key in sentiment_data for key in ["overall_sentiment", "confidence_score", "detected_emotions", "key_phrases_contributing_sentiment"]):
                    logger.warning(f"æƒ…æ„Ÿåˆ†æçš„ Gemini å›æ‡‰ JSON æ ¼å¼ä¸å®Œæ•´ï¼š{result_text}")
                    raise json.JSONDecodeError("ç¼ºå°‘å¿…è¦çš„éµ", result_text, 0)
                
                logger.info(f"æƒ…æ„Ÿåˆ†ææˆåŠŸï¼Œæ•´é«”æƒ…æ„Ÿ: {sentiment_data.get('overall_sentiment')} (ä¿¡å¿ƒåº¦: {sentiment_data.get('confidence_score')})")
                return sentiment_data
            except json.JSONDecodeError as json_err:
                logger.warning(f"æƒ…æ„Ÿåˆ†æçš„ Gemini å›æ‡‰ä¸æ˜¯æœ‰æ•ˆçš„ JSON æ ¼å¼ï¼š{result_text}ã€‚éŒ¯èª¤ï¼š{json_err}")
                # å¦‚æœä¸æ˜¯æœ‰æ•ˆ JSONï¼Œè¿”å›åŒ…å«åŸå§‹å›æ‡‰å’ŒéŒ¯èª¤è¨Šæ¯çš„å­—å…¸
                return {
                    "overall_sentiment": "unknown", # æƒ…æ„ŸæœªçŸ¥
                    "confidence_score": 0.0,
                    "detected_emotions": [],
                    "key_phrases_contributing_sentiment": [],
                    "error_message": "AI å›æ‡‰æ ¼å¼éé æœŸ JSONï¼Œç„¡æ³•å®Œæ•´è§£ææƒ…æ„Ÿã€‚",
                    "raw_response": result_text # åŒ…å«åŸå§‹å›æ‡‰ä»¥ä¾›é™¤éŒ¯
                }
                
        except Exception as e:
            logger.error(f"æƒ…æ„Ÿåˆ†æéç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}", exc_info=True)
            # å‘ä¸Šæ‹‹å‡ºä¾‹å¤–ï¼Œè®“å‘¼å«è€…è™•ç†æˆ–è¨˜éŒ„æ›´é«˜ç´šåˆ¥çš„éŒ¯èª¤
            raise Exception(f"æƒ…æ„Ÿåˆ†ææœå‹™å¤±æ•—ï¼š{str(e)}")
    
    async def extract_keywords(self, text: str) -> List[str]:
        """
        (å¯¦é©—æ€§åŠŸèƒ½) ä½¿ç”¨ Gemini å¾è¼¸å…¥æ–‡å­—ä¸­æå–é—œéµå­—ã€‚

        Args:
            text (str): éœ€è¦æå–é—œéµå­—çš„æ–‡å­—ã€‚

        Returns:
            List[str]: æå–åˆ°çš„é—œéµå­—åˆ—è¡¨ã€‚å¦‚æœæå–å¤±æ•—ï¼Œå‰‡è¿”å›ç©ºåˆ—è¡¨ã€‚
        """
        logger.info(f"é–‹å§‹å°é•·åº¦ç‚º {len(text)} çš„æ–‡æœ¬é€²è¡Œé—œéµå­—æå–ã€‚")
        try:
            # æç¤ºè©æŒ‡å°æ¨¡å‹æå–é—œéµå­—ï¼Œä¸¦æŒ‡å®šæ ¼å¼
            prompt = f"""
è«‹ä»”ç´°é–±è®€ä»¥ä¸‹æä¾›çš„æ–‡å­—å…§å®¹ï¼Œä¸¦å¾ä¸­æå–å‡ºæœ€é‡è¦çš„æ ¸å¿ƒé—œéµå­—æˆ–é—œéµçŸ­èªã€‚
è«‹è¿”å›ä¸€å€‹åˆ—è¡¨ï¼Œæ¯å€‹å…ƒç´ æ˜¯ä¸€å€‹é—œéµå­—/çŸ­èªã€‚
æœ€å¤šæå– 15 å€‹æœ€ç›¸é—œçš„é—œéµå­—/çŸ­èªã€‚
è«‹ç¢ºä¿æå–çš„é—œéµå­—å…·æœ‰ä»£è¡¨æ€§ï¼Œèƒ½å¤ æ¦‚æ‹¬æ–‡æœ¬çš„ä¸»è¦å…§å®¹ã€‚

æ–‡å­—å…§å®¹å¦‚ä¸‹ï¼š
---
{text[:5000]}
---

è«‹å°‡æå–åˆ°çš„é—œéµå­—/çŸ­èªä»¥ Python åˆ—è¡¨çš„å­—ä¸²è¡¨ç¤ºå½¢å¼è¼¸å‡ºï¼Œä¾‹å¦‚ï¼š
["é—œéµå­—1", "é—œéµçŸ­èª2", "æ ¸å¿ƒæ¦‚å¿µ3"]
"""
            # é™åˆ¶è¼¸å…¥æ–‡æœ¬é•·åº¦
            
            generation_config = genai_types.GenerationConfig(
                temperature=0.05, # éå¸¸ä½çš„æº«åº¦ä»¥ç²å–ç²¾ç¢ºå’Œç›¸é—œçš„é—œéµå­—
                max_output_tokens=512, # è¶³å¤ é—œéµå­—åˆ—è¡¨è¼¸å‡º
                top_p=0.7,
                top_k=5
            )
            
            response = await self._call_gemini_with_rotation(prompt, generation_config)
            result_text = self._extract_response_text(response, original_text=text[:5000], summary_type_for_log="é—œéµå­—æå–")
            
            # å˜—è©¦å°‡æ¨¡å‹å›æ‡‰ (æ‡‰ç‚ºåˆ—è¡¨çš„å­—ä¸²è¡¨ç¤º) è§£æç‚º Python åˆ—è¡¨
            try:
                # ä½¿ç”¨ json.loads æˆ– ast.literal_eval æ›´å®‰å…¨åœ°è§£æåˆ—è¡¨å­—ä¸²
                # æ­¤è™•å‡è¨­æ¨¡å‹èƒ½ç©©å®šè¼¸å‡º Python é¢¨æ ¼çš„åˆ—è¡¨å­—ä¸²
                # ä¾‹å¦‚ï¼š '["é—œéµå­—1", "é—œéµå­—2"]'
                # ç§»é™¤å¯èƒ½å­˜åœ¨æ–¼å­—ä¸²å‰å¾Œçš„éåˆ—è¡¨å­—å…ƒ (ä¾‹å¦‚æ¨¡å‹å¯èƒ½æ·»åŠ çš„èªªæ˜æ–‡å­—)
                if '[' in result_text and ']' in result_text:
                    list_str_part = result_text[result_text.find('['):result_text.rfind(']')+1]
                    keywords = json.loads(list_str_part) 
                    if isinstance(keywords, list) and all(isinstance(kw, str) for kw in keywords):
                        logger.info(f"é—œéµå­—æå–æˆåŠŸï¼Œå…±æå– {len(keywords)} å€‹é—œéµå­— (æœ€å¤šè¿”å›15å€‹)ã€‚")
                        return keywords[:15]  # æœ€å¤šè¿”å›15å€‹
                
                logger.warning(f"é—œéµå­—æå–çš„ Gemini å›æ‡‰æ ¼å¼éé æœŸåˆ—è¡¨å­—ä¸²ï¼š{result_text}")
                # å¦‚æœè§£æå¤±æ•—ï¼Œå˜—è©¦å¾æ›è¡Œç¬¦åˆ†å‰² (ä½œç‚ºå‚™ç”¨)
                keywords_fallback = [kw.strip('- ').strip().replace('"', '').replace("'", "") for kw in result_text.split('\n') if kw.strip()]
                if keywords_fallback:
                    logger.info(f"é—œéµå­—æå– (å‚™ç”¨è§£æ) æˆåŠŸï¼Œå…±æå– {len(keywords_fallback)} å€‹ã€‚")
                    return keywords_fallback[:15]
                return [] # è‹¥éƒ½å¤±æ•—å‰‡è¿”å›ç©ºåˆ—è¡¨

            except (json.JSONDecodeError, SyntaxError) as parse_err:
                logger.warning(f"è§£æé—œéµå­—åˆ—è¡¨æ™‚ç™¼ç”ŸéŒ¯èª¤: {parse_err}ã€‚åŸå§‹å›æ‡‰: {result_text}")
                # å¦‚æœè§£æå¤±æ•—ï¼Œå˜—è©¦ç°¡å–®çš„æ›è¡Œåˆ†å‰²
                keywords_fallback_simple = [line.strip('- ').strip().replace('"',"").replace("'","") for line in result_text.split('\n') if line.strip() and len(line.strip()) > 1]
                if keywords_fallback_simple:
                     logger.info(f"é—œéµå­—æå– (JSONè§£æå¤±æ•—å¾Œï¼Œæ›è¡Œåˆ†å‰²å‚™ç”¨) æˆåŠŸï¼Œå…±æå– {len(keywords_fallback_simple)} å€‹ã€‚")
                     return keywords_fallback_simple[:15]
                return []
            
        except Exception as e:
            logger.error(f"é—œéµå­—æå–éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {str(e)}", exc_info=True)
            return [] # ç™¼ç”ŸéŒ¯èª¤æ™‚è¿”å›ç©ºåˆ—è¡¨
    
    async def check_service_health_async(self) -> Dict[str, Any]: # æ–¹æ³•åèˆ‡å…¶ä»–æœå‹™ä¸€è‡´
        """
        æª¢æŸ¥ Google Gemini AI æœå‹™çš„å¥åº·ç‹€æ…‹ã€‚

        é€éç™¼é€ä¸€å€‹ç°¡å–®çš„æ¸¬è©¦è«‹æ±‚ä¾†åˆ¤æ–·æœå‹™æ˜¯å¦å¯ç”¨åŠå…¶é…ç½®ã€‚

        Returns:
            Dict[str, Any]: åŒ…å«æœå‹™å¥åº·ç‹€æ…‹çš„å­—å…¸ï¼Œ
                            ä¾‹å¦‚ `{"available": True, "model_configured": "gemini-pro", ...}` æˆ– `{"available": False, "error": "éŒ¯èª¤è¨Šæ¯"}`ã€‚
        """
        logger.info("é–‹å§‹æª¢æŸ¥ Google Gemini AI æœå‹™å¥åº·ç‹€æ…‹...")
        try:
            # ä½¿ç”¨ä¸€å€‹ç°¡å–®çš„æ¸¬è©¦æç¤ºè©å’Œé…ç½®
            test_prompt = "è«‹ç°¡çŸ­å›è¦† 'æ¸¬è©¦æˆåŠŸ' ä»¥ç¢ºèªæœå‹™å¯ç”¨æ€§ã€‚"
            test_generation_config = genai_types.GenerationConfig(
                temperature=0.0, # è¦æ±‚ç¢ºå®šæ€§å›è¦†
                max_output_tokens=50 # é™åˆ¶è¼¸å‡ºé•·åº¦ä»¥ç¯€çœè³‡æº
            )
            
            # _call_gemini_with_rotation å…§éƒ¨æœƒè™•ç† API é‡‘é‘°çš„è¨­å®šå’Œè¼ªæ›
            response = await self._call_gemini_with_rotation(test_prompt, test_generation_config)
            
            # é©—è­‰å›æ‡‰æ˜¯å¦ç¬¦åˆé æœŸ (é€™è£¡çš„æª¢æŸ¥æ¯”è¼ƒå¯¬é¬†ï¼Œä¸»è¦ç¢ºèªèƒ½é€šè¨ŠæˆåŠŸ)
            # _extract_response_text æœƒåœ¨å›æ‡‰ç„¡æ•ˆæ™‚æ‹‹å‡ºä¾‹å¤–
            extracted_text = self._extract_response_text(response, original_text=test_prompt, summary_type_for_log="å¥åº·æª¢æŸ¥")
            
            if extracted_text: # åªè¦æœ‰æˆåŠŸæå–åˆ°æ–‡æœ¬å°±èªç‚ºåŸºæœ¬å¯ç”¨
                logger.info(f"Google Gemini AI æœå‹™å¥åº·ç‹€æ…‹è‰¯å¥½ã€‚æ¸¬è©¦å›æ‡‰: '{extracted_text[:30]}...'")
                return {
                    "available": True,
                    "model_configured": self.model_name, # è¿”å›è¨­å®šä¸­ä½¿ç”¨çš„æ¨¡å‹åç¨±
                    "provider": "Google Gemini API via google-generativeai SDK",
                    "api_keys_available": len(self.api_keys), # è¿”å›è¨­å®šçš„ API é‡‘é‘°æ•¸é‡
                    "message": "æœå‹™é‹ä½œæ­£å¸¸ï¼Œå·²æˆåŠŸé€é API æ¸¬è©¦è«‹æ±‚ã€‚"
                }
            else: # ç†è«–ä¸Š _extract_response_text æœƒæ‹‹éŒ¯ï¼Œä½†å¤šä¸€å±¤é˜²è­·
                logger.warning("Google Gemini AI æœå‹™å¥åº·æª¢æŸ¥å¤±æ•—ï¼šAPI å›æ‡‰æœ‰æ•ˆä½†æå–æ–‡æœ¬ç‚ºç©ºã€‚")
                return {
                    "available": False,
                    "model_configured": self.model_name,
                    "error": "API å›æ‡‰æœ‰æ•ˆä½†æœªèƒ½æå–åˆ°æ¸¬è©¦æ–‡æœ¬ï¼Œæœå‹™å¯èƒ½éƒ¨åˆ†ä¸å¯ç”¨ã€‚"
                }
                
        except Exception as e:
            logger.error(f"Google Gemini AI æœå‹™å¥åº·æª¢æŸ¥æ™‚ç™¼ç”Ÿåš´é‡éŒ¯èª¤: {str(e)}", exc_info=True)
            return {
                "available": False,
                "model_configured": self.model_name,
                "error": f"æœå‹™æª¢æŸ¥æ™‚ç™¼ç”Ÿä¾‹å¤–: {type(e).__name__} - {str(e)}"
            }